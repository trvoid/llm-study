{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNZ3y78jzXbpSmLBC0mDN3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2345c97cf9e4f4a9c1a1344c928fdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4088c8d15fb41efb56ca8295c7f25b5",
              "IPY_MODEL_87df2842719045488595c9725e386297",
              "IPY_MODEL_6de2a2c502be4e4fa4770ea0eb4fe94e"
            ],
            "layout": "IPY_MODEL_85e055a4dcaf4131ad4cad24b5b2410c"
          }
        },
        "a4088c8d15fb41efb56ca8295c7f25b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32fa3ff8af104c4d9f23ed652c721e20",
            "placeholder": "​",
            "style": "IPY_MODEL_30d72eedc6714e21a7f200cb0abcfd33",
            "value": "Map: 100%"
          }
        },
        "87df2842719045488595c9725e386297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9c813e80fc43b096bda875f665b176",
            "max": 10570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ade48e3bc6d4a46a86b599e87ea406b",
            "value": 10570
          }
        },
        "6de2a2c502be4e4fa4770ea0eb4fe94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eabe883b07b4d968dd2cd8bff9ca264",
            "placeholder": "​",
            "style": "IPY_MODEL_6de4057a54f84d10a3dcc7e0535a86e5",
            "value": " 10570/10570 [00:15&lt;00:00, 788.93 examples/s]"
          }
        },
        "85e055a4dcaf4131ad4cad24b5b2410c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fa3ff8af104c4d9f23ed652c721e20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30d72eedc6714e21a7f200cb0abcfd33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed9c813e80fc43b096bda875f665b176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ade48e3bc6d4a46a86b599e87ea406b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eabe883b07b4d968dd2cd8bff9ca264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de4057a54f84d10a3dcc7e0535a86e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trvoid/llm-study/blob/main/bert/getting_started_with_distilbert_for_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DistilBERT for QA 시작하기\n",
        "\n",
        "이 실습은 아래 문서의 내용을 토대로 진행하였습니다.\n",
        "\n",
        "* [Fine-Tuning DistilBERT for Question Answering](https://machinelearningmastery.com/fine-tuning-distilbert-for-question-answering/), By Muhammad Asad Iqbal Khan on March 29, 2025"
      ],
      "metadata": {
        "id": "9cvu_6JOiK0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 해결하고자 하는 문제\n",
        "\n",
        "다음과 같은 유형의 문제를 언어 모델을 사용하여 풀고자 합니다.\n",
        "\n",
        "* 지문(context): Tom sits on a bench.\n",
        "* 질문(question): Where does Tom sit?\n",
        "* 답변(answer): bench (지문에서 첫번째 문자의 위치를 0이라고 할 때 답변의 시작 위치는 14, 끝 위치는 19)"
      ],
      "metadata": {
        "id": "_4PMWlGHibc1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WekkNEWOh0OC",
        "outputId": "3952d28b-0f0c-4b2d-da72-dd0aae3d5782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_char=14, end_char=19\n"
          ]
        }
      ],
      "source": [
        "context = \"Tom sits on a bench.\"\n",
        "answer = \"bench\"\n",
        "\n",
        "start_char = context.find(answer)\n",
        "end_char = start_char + len(answer)\n",
        "print(f\"start_char={start_char}, end_char={end_char}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "주어진 지문으로부터 질문에 답변하는 방식에 따라 아래 두 가지로 구분할 수 있습니다.\n",
        "\n",
        "* 추출형 질의응답 (Extractive Question Answering): 주어진 지문 내에서 질문에 대한 답변에 해당하는 부분을 그대로 찾아 추출하는 방식\n",
        "* 생성형 질의응답 (Abstractive Question Answering): 주어진 지문의 내용을 이해하고 요약하거나 재구성하여 질문에 대한 답변을 새롭게 생성하는 방식\n",
        "\n",
        "여기서 다루는 문제는 추출형 질의응답에 해당합니다."
      ],
      "metadata": {
        "id": "YerIbsCNm9wH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 문제 해결 방안\n",
        "\n",
        "언어 모델 훈련에 사용할 데이터를 아래의 형식에 맞추어 준비합니다.\n",
        "\n",
        "* 입력 데이터: 질문과 지문을 토큰화하고 이어붙인 배열\n",
        "  * \"[CLS] *question* [SEP] *context* [SEP]\"\n",
        "* 정답 데이터: 입력 데이터에서 답변의 시작 토큰과 끝 토큰의 위치 정보\n",
        "  * 입력 데이터에서 답변의 시작 토큰 위치\n",
        "  * 입력 데이터에서 답변의 끝 토큰 위치\n",
        "\n",
        "위 형식의 데이터를 대상으로 훈련하는 과정은 다음과 같습니다.\n",
        "\n",
        "* 모델과 데이터셋 선택\n",
        "  * 언어 이해를 목적으로 훈련된 기본 모델 선택\n",
        "  * 질의응답 작업을 위해 미세조정 훈련을 수행할 모델 선택\n",
        "  * 질의응답 미세조정 훈련에 사용할 데이터셋 선택\n",
        "* 미세조정 훈련\n",
        "  1. 미세조정 모델로 정답을 예측하고 손실 계산\n",
        "  2. 미세조정 모델 파라미터 갱신\n",
        "\n",
        "이 실습에서 사용할 모델과 데이터셋은 다음과 같습니다.\n",
        "\n",
        "1. [DistilBERT](https://huggingface.co/docs/transformers/en/model_doc/distilbert):기본 모델 (단어에 대한 단순 임베딩이 아니라 맥락을 고려한 임베딩 수행)\n",
        "2. [DistilBertForQuestionAnswering](https://huggingface.co/docs/transformers/en/model_doc/distilbert?usage=Pipeline#transformers.DistilBertForQuestionAnswering): DistilBERT 모델에 질의응답 층을 추가한 것으로서 질의응답 미세조정 훈련을 위한 모델\n",
        "3. [SQuAD](https://huggingface.co/datasets/rajpurkar/squad): 질의응답 미세조정 훈련을 위한 데이터셋"
      ],
      "metadata": {
        "id": "hLRK87J4oijH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 데이터셋 적재"
      ],
      "metadata": {
        "id": "8wjt9JTaBkod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`datasets` 라이브러리를 설치합니다."
      ],
      "metadata": {
        "id": "UDwsB6s4lTMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB02kkoqvW08",
        "outputId": "30176221-d22f-403c-9ae8-677cd8996e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`squad` 데이터셋을 적재합니다."
      ],
      "metadata": {
        "id": "NPqrfHggldKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the SQuAD dataset\n",
        "dataset = load_dataset(\"squad\")"
      ],
      "metadata": {
        "id": "jT4hoDawu1Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`dataset`의 구조를 출력해서 확인합니다."
      ],
      "metadata": {
        "id": "DtE0YtRFk6md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl-pxd78vrij",
        "outputId": "e20632a3-d9a9-437c-9320-810dfde54b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 87599\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 10570\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"train\" 항목의 첫번째 데이터를 출력해서 실제로 어떤 값을 가지고 있는지 확인합니다."
      ],
      "metadata": {
        "id": "CSb5USfCkbPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(json.dumps(dataset[\"train\"][0], indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yza3i4GpIFzP",
        "outputId": "0e55d4f4-b409-44cc-e38d-2d45d75d1684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"id\": \"5733be284776f41900661182\",\n",
            "    \"title\": \"University_of_Notre_Dame\",\n",
            "    \"context\": \"Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \\\"Venite Ad Me Omnes\\\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\",\n",
            "    \"question\": \"To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\",\n",
            "    \"answers\": {\n",
            "        \"text\": [\n",
            "            \"Saint Bernadette Soubirous\"\n",
            "        ],\n",
            "        \"answer_start\": [\n",
            "            515\n",
            "        ]\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 토크나이저와 모델 적재"
      ],
      "metadata": {
        "id": "cuvzgR2fC3-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`transformers` 라이브러리를 설치합니다."
      ],
      "metadata": {
        "id": "B5mFZO1ZmAnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poX7Xe7pEOso",
        "outputId": "cc737986-a986-4e65-a0fa-68b92b03753f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 모델 `distilbert-base-uncased`를 지정하고 `DistilBertTokenizerFast` 클래스를 사용하여 토크나이저를, `DistilBertForQuestionAnswering` 클래스를 사용하여 모델을 적재합니다."
      ],
      "metadata": {
        "id": "Vo6UslWcmIpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
        "\n",
        "# Load tokenizer and model\n",
        "base_model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(base_model_name)\n",
        "model = DistilBertForQuestionAnswering.from_pretrained(base_model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zADW5Gsu-Gb",
        "outputId": "c9740f3f-c8cf-43cc-aae3-587b9d282916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 토크나이저 테스트\n",
        "\n",
        "훈련 데이터 준비 과정에 대한 이해를 돕기 위하여 간단한 예제로 토크나이저를 테스트해 봅니다."
      ],
      "metadata": {
        "id": "W2H3lSaUFL81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\"Where does Tom sits?\"]\n",
        "contexts = [\"Tom sits on a bench.\"]\n",
        "\n",
        "inputs = tokenizer(\n",
        "        questions,\n",
        "        contexts,\n",
        "        max_length=15,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        ")"
      ],
      "metadata": {
        "id": "O4PgV3IaEoVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "토크나이저 실행 결과인 `inputs`의 유형과 키 항목들을 출력합니다."
      ],
      "metadata": {
        "id": "pbXDTqCZpKrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(inputs))\n",
        "print(inputs.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrIII6NIpRwa",
        "outputId": "06fffcfa-8cc2-4220-f607-437214d7a379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
            "dict_keys(['input_ids', 'attention_mask', 'offset_mapping'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각각의 키 항목들에 해당하는 값을 출력하면 다음과 같습니다."
      ],
      "metadata": {
        "id": "0HioUORAqFN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"input_ids: \", end=\"\")\n",
        "print(inputs[\"input_ids\"])\n",
        "\n",
        "print(\"attention_mask: \", end=\"\")\n",
        "print(inputs[\"attention_mask\"])\n",
        "\n",
        "print(\"offset_mapping: \", end=\"\")\n",
        "print(inputs[\"offset_mapping\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYS25q6opxHd",
        "outputId": "493b2f82-85ef-4441-9ec6-86d2ffa06a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [[101, 2073, 2515, 3419, 7719, 1029, 102, 3419, 7719, 2006, 1037, 6847, 1012, 102, 0]]\n",
            "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]\n",
            "offset_mapping: [[(0, 0), (0, 5), (6, 10), (11, 14), (15, 19), (19, 20), (0, 0), (0, 3), (4, 8), (9, 11), (12, 13), (14, 19), (19, 20), (0, 0), (0, 0)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`input_ids`에 해당하는 값을 토큰 문자열로 변환해서 보면 각각의 키 항목들의 의미를 좀 더 쉽게 이해할 수 있습니다."
      ],
      "metadata": {
        "id": "a81S7uWiqPpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_strs = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "print(\"token_strs: \", end=\"\")\n",
        "print(token_strs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5UmQXnyFwhf",
        "outputId": "2beee27a-a4ff-4b36-e4bb-912bd3a9aa19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_strs: ['[CLS]', 'where', 'does', 'tom', 'sits', '?', '[SEP]', 'tom', 'sits', 'on', 'a', 'bench', '.', '[SEP]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`token_strs`을 살펴 보면 답변에 해당하는 토큰 'bench'의 시작 위치와 끝 위치가  각각 11임을 알 수 있습니다."
      ],
      "metadata": {
        "id": "VZB_TDAzq7fz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 토큰 배열에서 답변의 시작 토큰 위치와 끝 토큰 위치 찾는 방법\n",
        "\n",
        "토크나이저 출력 결과 중에서 활용해야 할 정보가 하나 더 있는데 그것은 sequence_ids입니다. 이것으로부터 각각의 토큰이 토크나이저에 입력한 문자열들 중에서 몇 번째 문자열에 해당하는 것인지 파악할 수 있습니다.\n",
        "\n",
        "* sequence_ids의 값이 0이면 토크나이저의 첫번째 인자(`questions`)로부터 온 토큰\n",
        "* sequence_ids의 값이 1이면 토크나이저의 두번째 인자(`contexts`)로부터 온 토큰"
      ],
      "metadata": {
        "id": "EI6-4E_lK9UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"type(sequence_ids): \", end=\"\")\n",
        "print(type(inputs.sequence_ids))\n",
        "\n",
        "print(\"sequence_ids(0): \", end=\"\")\n",
        "print(inputs.sequence_ids(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GizydGWep4-2",
        "outputId": "8e755e94-b887-4471-c045-739a55f6c4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(sequence_ids): <class 'method'>\n",
            "sequence_ids(0): [None, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, None, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 토큰 배열에서 답변의 시작 토큰 위치와 끝 토큰 위치를 찾기 위해 필요로 하는 정보는 모두 확보하였습니다.\n",
        "\n",
        "* `inputs.sequence_ids(0): [None, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, None, None]`\n",
        "* `inputs[\"offset_mapping\"][0]: [(0, 0), (0, 5), (6, 10), (11, 14), (15, 19), (19, 20), (0, 0), (0, 3), (4, 8), (9, 11), (12, 13), (14, 19), (19, 20), (0, 0), (0, 0)]`\n",
        "* `start_char: 14`\n",
        "* `end_char: 19`\n",
        "\n",
        "이 정보들을 활용하여 답변의 위치를 기계적으로 찾는 과정은 다음과 같습니다.\n",
        "\n",
        "1. sequence_ids에서 context에 해당하는 토큰들 위치 찾기\n",
        "  1. 값이 1인 요소들 중에서 첫번째 것의 위치: `7`\n",
        "  2. 값이 1인 요소들 중에서 마지막 것의 위치: `12`\n",
        "2. offset_mapping에서 context에 해당하는 토큰들을 대상으로 답변의 시작 위치와 끝 위치에 해당하는 토큰 위치 찾기\n",
        "  1. `start_char` 값인 14를 포함하는 offset_mapping 튜플의 위치: `11`\n",
        "  2. `end_char` 값인 19를 포함하는 offset_mapping 튜플의 위치: `11`\n",
        "\n",
        "답변의 시작 토큰 위치와 끝 토큰의 위치가 훈련 데이터에서 입력 데이터에 대한 정답으로 간주되는 값입니다."
      ],
      "metadata": {
        "id": "yKCMy2scrHxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 훈련 데이터 생성\n",
        "\n",
        "원본 데이터셋에서 개별 데이터 항목은 아래와 같은 구조를 가집니다."
      ],
      "metadata": {
        "id": "YiXcWOvnTjn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples_like_squad = [\n",
        "    {\n",
        "        \"context\": \"Tom sits on a bench.\",\n",
        "        \"question\": \"Where does Tom sit?\",\n",
        "        \"answers\": {\n",
        "            \"text\": [\"bench\"],\n",
        "            \"answer_start\": [14]\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "G8hKTEhUwnct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련용 데이터 형식으로 변환하는 전처리 함수는 아래와 같은 구조의 데이터를 인자로 받아서 처리합니다."
      ],
      "metadata": {
        "id": "cf61oon22l5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples_for_preprocess = {\n",
        "    \"context\": [\"Tom sits on a bench.\"],\n",
        "    \"question\": [\"Where does Tom sit?\"],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"text\": [\"bench\"],\n",
        "            \"answer_start\": [14]\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "LdjcAFdP0PpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터셋을 입력으로 받아서 토큰 배열로 만들고 답변의 시작 토큰 위치와 끝 토큰의 위치를 찾아서 훈련용 데이터를 만드는 전처리 함수의 구현은 다음과 같습니다."
      ],
      "metadata": {
        "id": "G7VZuSSI3hyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the dataset\n",
        "def preprocess_function(examples, max_length=384):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
        "    answers = examples[\"answers\"]\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        answer = answers[i]\n",
        "        start_char = answer[\"answer_start\"][0]\n",
        "        end_char = start_char + len(answer[\"text\"][0])\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "\n",
        "        # Find the start and end of the context\n",
        "        context_start = sequence_ids.index(1)\n",
        "        context_end = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)\n",
        "\n",
        "        # If the answer is not fully inside the context, label it (0, 0)\n",
        "        if offsets[context_start][0] > end_char or offsets[context_end][1] < start_char:\n",
        "            start_positions.append(0)\n",
        "            end_positions.append(0)\n",
        "        else:\n",
        "            # Otherwise find the start and end token positions\n",
        "            idx = context_start\n",
        "            while idx <= context_end and offsets[idx][0] <= start_char:\n",
        "                idx += 1\n",
        "            start_positions.append(idx - 1)\n",
        "\n",
        "            idx = context_end\n",
        "            while idx >= context_start and offsets[idx][1] >= end_char:\n",
        "                idx -= 1\n",
        "            end_positions.append(idx + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "2r1EwGLZvFAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위에서 준비한 테스트용 데이터셋을 사용하여 전처리 함수를 실행해 봅니다. 화면 표시의 편의를 위하여 `max_length`의 값을 15로 지정하였습니다."
      ],
      "metadata": {
        "id": "pGFucTtw3-Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = preprocess_function(examples_for_preprocess, max_length=15)\n",
        "print(f'input_ids: {results[\"input_ids\"]}')\n",
        "print(f'attention_mask: {results[\"attention_mask\"]}')\n",
        "print(f'start_positions: {results[\"start_positions\"]}')\n",
        "print(f'end_positions: {results[\"end_positions\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHGyiwPaUKZU",
        "outputId": "7bb63427-7e0f-4993-c6ef-f788a9779ea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [[101, 2073, 2515, 3419, 4133, 1029, 102, 3419, 7719, 2006, 1037, 6847, 1012, 102, 0]]\n",
            "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]\n",
            "start_positions: [11]\n",
            "end_positions: [11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing to the dataset\n",
        "tokenized_datasets = dataset.map(preprocess_function,\n",
        "                                 batched=True,\n",
        "                                 remove_columns=dataset[\"train\"].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d2345c97cf9e4f4a9c1a1344c928fdf0",
            "a4088c8d15fb41efb56ca8295c7f25b5",
            "87df2842719045488595c9725e386297",
            "6de2a2c502be4e4fa4770ea0eb4fe94e",
            "85e055a4dcaf4131ad4cad24b5b2410c",
            "32fa3ff8af104c4d9f23ed652c721e20",
            "30d72eedc6714e21a7f200cb0abcfd33",
            "ed9c813e80fc43b096bda875f665b176",
            "1ade48e3bc6d4a46a86b599e87ea406b",
            "8eabe883b07b4d968dd2cd8bff9ca264",
            "6de4057a54f84d10a3dcc7e0535a86e5"
          ]
        },
        "id": "GqJYhmQOT4Vc",
        "outputId": "7ae35b34-aef5-463d-cb21-5aa9cd97a4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2345c97cf9e4f4a9c1a1344c928fdf0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 미세조정 훈련\n",
        "\n",
        "이제 SQuAD 데이터셋을 대상으로 DistilBertForQuestionAnswering 모델을 훈련합니다."
      ],
      "metadata": {
        "id": "fYA38CqSWOYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EZmfn1Afm36",
        "outputId": "77251fbf-6eb2-4883-d3ec-13a4e76b841a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Train the model and save the results\n",
        "trainer.train()\n",
        "\n",
        "finetuned_model_path = \"./fine-tuned-distilbert-squad\"\n",
        "model.save_pretrained(finetuned_model_path)\n",
        "tokenizer.save_pretrained(finetuned_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jlTnf83-T_xf",
        "outputId": "472dbaf4-5e88-4834-cec6-147aa9e3b320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-646e4541d1be>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Initialize Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m trainer = Trainer(\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. 미세조정 훈련 모델로 질의응답 수행"
      ],
      "metadata": {
        "id": "OZdlfDhR5Lj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_answer(tokenizer, model, context, question):\n",
        "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
        "    input_tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    print(input_tokens)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    answer_start_index = outputs.start_logits.argmax()\n",
        "    answer_end_index = outputs.end_logits.argmax()\n",
        "\n",
        "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "    output_tokens = tokenizer.convert_ids_to_tokens(predict_answer_tokens)\n",
        "\n",
        "    return output_tokens"
      ],
      "metadata": {
        "id": "JwbCfrNC5bAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 기본 모델로 질의응답을 수행해 봅니다."
      ],
      "metadata": {
        "id": "tmJKDKhkYncw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_context = \"Jim Henson was a nice puppet\"\n",
        "test_question = \"Who was Jim Henson?\"\n",
        "\n",
        "base_tokenizer = DistilBertTokenizerFast.from_pretrained(base_model_name)\n",
        "base_model = DistilBertForQuestionAnswering.from_pretrained(base_model_name)\n",
        "\n",
        "test_output_tokens = predict_answer(base_tokenizer, base_model, test_context, test_question)\n",
        "print(f\"answer by base model: {test_output_tokens}\")"
      ],
      "metadata": {
        "id": "mTL_JdURYFCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 미세조정 모델로 답변을 예측하고 기본 모델 예측 결과와 비교합니다."
      ],
      "metadata": {
        "id": "74uJn51vYvbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_tokenizer = DistilBertTokenizerFast.from_pretrained(finetuned_model_path)\n",
        "finetuned_model = DistilBertForQuestionAnswering.from_pretrained(finetuned_model_path)\n",
        "\n",
        "test_output_tokens = predict_answer(finetuned_tokenizer, finetuned_model, test_context, test_question)\n",
        "print(f\"answer by finetuned model: {test_output_tokens}\")"
      ],
      "metadata": {
        "id": "jbO3_1mPYbf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}