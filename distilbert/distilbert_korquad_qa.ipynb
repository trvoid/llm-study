{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/trvoid/llm-study/blob/main/bert/getting_started_with_distilbert_for_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cvu_6JOiK0j"
   },
   "source": [
    "# DistilBERT for QA ì‹œì‘í•˜ê¸° (í•œêµ­ì–´)\n",
    "\n",
    "**ë…¸íŠ¸: distilbert-base-multilingual-casedë¥¼ ê¸°ë³¸ ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ì˜€ìŒ**\n",
    "\n",
    "ì´ ì‹¤ìŠµì€ ì•„ë˜ ë¬¸ì„œì˜ ë‚´ìš©ì„ í† ëŒ€ë¡œ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "* [Fine-Tuning DistilBERT for Question Answering](https://machinelearningmastery.com/fine-tuning-distilbert-for-question-answering/), By Muhammad Asad Iqbal Khan on March 29, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4PMWlGHibc1"
   },
   "source": [
    "## 1. í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œ\n",
    "\n",
    "ë‹¤ìŒê³¼ ê°™ì€ ìœ í˜•ì˜ ë¬¸ì œë¥¼ ì–¸ì–´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í’€ê³ ì í•©ë‹ˆë‹¤.\n",
    "\n",
    "* ì§€ë¬¸(context): ê³ ì–‘ì´ê°€ ì˜ìì— ì•‰ìŠµë‹ˆë‹¤.\n",
    "* ì§ˆë¬¸(question): ê³ ì–‘ì´ê°€ ì–´ë””ì— ì•‰ìŠµë‹ˆê¹Œ?\n",
    "* ë‹µë³€(answer): ì˜ì (ì§€ë¬¸ì—ì„œ ì²«ë²ˆì§¸ ë¬¸ìì˜ ìœ„ì¹˜ë¥¼ 0ì´ë¼ê³  í•  ë•Œ ë‹µë³€ì˜ ì‹œì‘ ìœ„ì¹˜ëŠ” 5, ë ìœ„ì¹˜ëŠ” 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WekkNEWOh0OC",
    "outputId": "3952d28b-0f0c-4b2d-da72-dd0aae3d5782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_char=5, end_char=7\n"
     ]
    }
   ],
   "source": [
    "context = \"ê³ ì–‘ì´ê°€ ì˜ìì— ì•‰ìŠµë‹ˆë‹¤.\"\n",
    "answer = \"ì˜ì\"\n",
    "\n",
    "start_char = context.find(answer)\n",
    "end_char = start_char + len(answer)\n",
    "print(f\"start_char={start_char}, end_char={end_char}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YerIbsCNm9wH"
   },
   "source": [
    "ì£¼ì–´ì§„ ì§€ë¬¸ìœ¼ë¡œë¶€í„° ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë°©ì‹ì— ë”°ë¼ ì•„ë˜ ë‘ ê°€ì§€ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* ì¶”ì¶œí˜• ì§ˆì˜ì‘ë‹µ (Extractive Question Answering): ì£¼ì–´ì§„ ì§€ë¬¸ ë‚´ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ ê·¸ëŒ€ë¡œ ì°¾ì•„ ì¶”ì¶œí•˜ëŠ” ë°©ì‹\n",
    "* ìƒì„±í˜• ì§ˆì˜ì‘ë‹µ (Abstractive Question Answering): ì£¼ì–´ì§„ ì§€ë¬¸ì˜ ë‚´ìš©ì„ ì´í•´í•˜ê³  ìš”ì•½í•˜ê±°ë‚˜ ì¬êµ¬ì„±í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒˆë¡­ê²Œ ìƒì„±í•˜ëŠ” ë°©ì‹\n",
    "\n",
    "ì—¬ê¸°ì„œ ë‹¤ë£¨ëŠ” ë¬¸ì œëŠ” ì¶”ì¶œí˜• ì§ˆì˜ì‘ë‹µì— í•´ë‹¹í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLRK87J4oijH"
   },
   "source": [
    "## 2. ë¬¸ì œ í•´ê²° ë°©ì•ˆ\n",
    "\n",
    "ì–¸ì–´ ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©í•  ë°ì´í„°ë¥¼ ì•„ë˜ì˜ í˜•ì‹ì— ë§ì¶”ì–´ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "\n",
    "* ì…ë ¥ ë°ì´í„°: ì§ˆë¬¸ê³¼ ì§€ë¬¸ì„ í† í°í™”í•˜ê³  ì´ì–´ë¶™ì¸ ë°°ì—´\n",
    "  * \"[CLS] *question* [SEP] *context* [SEP]\"\n",
    "* ì •ë‹µ ë°ì´í„°: ì…ë ¥ ë°ì´í„°ì—ì„œ ë‹µë³€ì˜ ì‹œì‘ í† í°ê³¼ ë í† í°ì˜ ìœ„ì¹˜ ì •ë³´\n",
    "  * ì…ë ¥ ë°ì´í„°ì—ì„œ ë‹µë³€ì˜ ì‹œì‘ í† í° ìœ„ì¹˜\n",
    "  * ì…ë ¥ ë°ì´í„°ì—ì„œ ë‹µë³€ì˜ ë í† í° ìœ„ì¹˜\n",
    "\n",
    "ìœ„ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ í›ˆë ¨í•˜ëŠ” ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "* ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ ì„ íƒ\n",
    "  * ì–¸ì–´ ì´í•´ë¥¼ ëª©ì ìœ¼ë¡œ í›ˆë ¨ëœ ê¸°ë³¸ ëª¨ë¸ ì„ íƒ\n",
    "  * ì§ˆì˜ì‘ë‹µ ì‘ì—…ì„ ìœ„í•´ ë¯¸ì„¸ì¡°ì • í›ˆë ¨ì„ ìˆ˜í–‰í•  ëª¨ë¸ ì„ íƒ\n",
    "  * ì§ˆì˜ì‘ë‹µ ë¯¸ì„¸ì¡°ì • í›ˆë ¨ì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ ì„ íƒ\n",
    "* ë¯¸ì„¸ì¡°ì • í›ˆë ¨\n",
    "  1. ë¯¸ì„¸ì¡°ì • ëª¨ë¸ë¡œ ì •ë‹µì„ ì˜ˆì¸¡í•˜ê³  ì†ì‹¤ ê³„ì‚°\n",
    "  2. ë¯¸ì„¸ì¡°ì • ëª¨ë¸ íŒŒë¼ë¯¸í„° ê°±ì‹ \n",
    "\n",
    "ì´ ì‹¤ìŠµì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. [DistilBERT](https://huggingface.co/docs/transformers/en/model_doc/distilbert):ê¸°ë³¸ ëª¨ë¸ (ë‹¨ì–´ì— ëŒ€í•œ ë‹¨ìˆœ ì„ë² ë”©ì´ ì•„ë‹ˆë¼ ë§¥ë½ì„ ê³ ë ¤í•œ ì„ë² ë”© ìˆ˜í–‰)\n",
    "2. [DistilBertForQuestionAnswering](https://huggingface.co/docs/transformers/en/model_doc/distilbert?usage=Pipeline#transformers.DistilBertForQuestionAnswering): DistilBERT ëª¨ë¸ì— ì§ˆì˜ì‘ë‹µ ì¸µì„ ì¶”ê°€í•œ ê²ƒìœ¼ë¡œì„œ ì§ˆì˜ì‘ë‹µ ë¯¸ì„¸ì¡°ì • í›ˆë ¨ì„ ìœ„í•œ ëª¨ë¸\n",
    "3. [KorQuAD 1.0](https://huggingface.co/datasets/KorQuAD/squad_kor_v1): ì§ˆì˜ì‘ë‹µ ë¯¸ì„¸ì¡°ì • í›ˆë ¨ì„ ìœ„í•œ ë°ì´í„°ì…‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wjt9JTaBkod"
   },
   "source": [
    "## 3. ë°ì´í„°ì…‹ ì ì¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDwsB6s4lTMM"
   },
   "source": [
    "`datasets` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oB02kkoqvW08",
    "outputId": "30176221-d22f-403c-9ae8-677cd8996e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (0.26.0)\n",
      "Requirement already satisfied: packaging in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from aiohttp->datasets) (1.15.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPqrfHggldKK"
   },
   "source": [
    "KorQuAD ë°ì´í„°ì…‹ì„ ì ì¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jT4hoDawu1Sx"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the KorQuAD dataset\n",
    "dataset = load_dataset(\"KorQuAD/squad_kor_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtE0YtRFk6md"
   },
   "source": [
    "`dataset`ì˜ êµ¬ì¡°ë¥¼ ì¶œë ¥í•´ì„œ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bl-pxd78vrij",
    "outputId": "e20632a3-d9a9-437c-9320-810dfde54b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 60407\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 5774\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSb5USfCkbPl"
   },
   "source": [
    "\"train\" í•­ëª©ì˜ ì²«ë²ˆì§¸ ë°ì´í„°ë¥¼ ì¶œë ¥í•´ì„œ ì‹¤ì œë¡œ ì–´ë–¤ ê°’ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yza3i4GpIFzP",
    "outputId": "0e55d4f4-b409-44cc-e38d-2d45d75d1684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"6566495-0-0\",\n",
      "    \"title\": \"íŒŒìš°ìŠ¤íŠ¸_ì„œê³¡\",\n",
      "    \"context\": \"1839ë…„ ë°”ê·¸ë„ˆëŠ” ê´´í…Œì˜ íŒŒìš°ìŠ¤íŠ¸ì„ ì²˜ìŒ ì½ê³  ê·¸ ë‚´ìš©ì— ë§ˆìŒì´ ëŒë ¤ ì´ë¥¼ ì†Œì¬ë¡œ í•´ì„œ í•˜ë‚˜ì˜ êµí–¥ê³¡ì„ ì“°ë ¤ëŠ” ëœ»ì„ ê°–ëŠ”ë‹¤. ì´ ì‹œê¸° ë°”ê·¸ë„ˆëŠ” 1838ë…„ì— ë¹› ë…ì´‰ìœ¼ë¡œ ì‚°ì „ìˆ˜ì „ì„ ë‹¤ ê±²ì€ ìƒí™©ì´ë¼ ì¢Œì ˆê³¼ ì‹¤ë§ì— ê°€ë“í–ˆìœ¼ë©° ë©”í”¼ìŠ¤í† í ë ˆìŠ¤ë¥¼ ë§Œë‚˜ëŠ” íŒŒìš°ìŠ¤íŠ¸ì˜ ì‹¬ê²½ì— ê³µê°í–ˆë‹¤ê³  í•œë‹¤. ë˜í•œ íŒŒë¦¬ì—ì„œ ì•„ë¸Œë„¤í¬ì˜ ì§€íœ˜ë¡œ íŒŒë¦¬ ìŒì•…ì› ê´€í˜„ì•…ë‹¨ì´ ì—°ì£¼í•˜ëŠ” ë² í† ë²¤ì˜ êµí–¥ê³¡ 9ë²ˆì„ ë“£ê³  ê¹Šì€ ê°ëª…ì„ ë°›ì•˜ëŠ”ë°, ì´ê²ƒì´ ì´ë“¬í•´ 1ì›”ì— íŒŒìš°ìŠ¤íŠ¸ì˜ ì„œê³¡ìœ¼ë¡œ ì“°ì—¬ì§„ ì´ ì‘í’ˆì— ì¡°ê¸ˆì´ë¼ë„ ì˜í–¥ì„ ë¼ì³¤ìœ¼ë¦¬ë¼ëŠ” ê²ƒì€ ì˜ì‹¬í•  ì—¬ì§€ê°€ ì—†ë‹¤. ì—¬ê¸°ì˜ ë¼ë‹¨ì¡° ì¡°ì„±ì˜ ê²½ìš°ì—ë„ ê·¸ì˜ ì „ê¸°ì— ì í˜€ ìˆëŠ” ê²ƒì²˜ëŸ¼ ë‹¨ìˆœí•œ ì •ì‹ ì  í”¼ë¡œë‚˜ ì‹¤ì˜ê°€ ë°˜ì˜ëœ ê²ƒì´ ì•„ë‹ˆë¼ ë² í† ë²¤ì˜ í•©ì°½êµí–¥ê³¡ ì¡°ì„±ì˜ ì˜í–¥ì„ ë°›ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ê·¸ë ‡ê²Œ êµí–¥ê³¡ ì‘ê³¡ì„ 1839ë…„ë¶€í„° 40ë…„ì— ê±¸ì³ íŒŒë¦¬ì—ì„œ ì°©ìˆ˜í–ˆìœ¼ë‚˜ 1ì•…ì¥ì„ ì“´ ë’¤ì— ì¤‘ë‹¨í–ˆë‹¤. ë˜í•œ ì‘í’ˆì˜ ì™„ì„±ê³¼ ë™ì‹œì— ê·¸ëŠ” ì´ ì„œê³¡(1ì•…ì¥)ì„ íŒŒë¦¬ ìŒì•…ì›ì˜ ì—°ì£¼íšŒì—ì„œ ì—°ì£¼í•  íŒŒíŠ¸ë³´ê¹Œì§€ ì¤€ë¹„í•˜ì˜€ìœ¼ë‚˜, ì‹¤ì œë¡œëŠ” ì´ë£¨ì–´ì§€ì§€ëŠ” ì•Šì•˜ë‹¤. ê²°êµ­ ì´ˆì—°ì€ 4ë…„ ë°˜ì´ ì§€ë‚œ í›„ì— ë“œë ˆìŠ¤ë´ì—ì„œ ì—°ì£¼ë˜ì—ˆê³  ì¬ì—°ë„ ì´ë£¨ì–´ì¡Œì§€ë§Œ, ì´í›„ì— ê·¸ëŒ€ë¡œ ë°©ì¹˜ë˜ê³  ë§ì•˜ë‹¤. ê·¸ ì‚¬ì´ì— ê·¸ëŠ” ë¦¬ì—”ì¹˜ì™€ ë°©í™©í•˜ëŠ” ë„¤ëœë€ë“œì¸ì„ ì™„ì„±í•˜ê³  íƒ„í˜¸ì´ì €ì—ë„ ì°©ìˆ˜í•˜ëŠ” ë“± ë¶„ì£¼í•œ ì‹œê°„ì„ ë³´ëƒˆëŠ”ë°, ê·¸ëŸ° ë°”ìœ ìƒí™œì´ ì´ ê³¡ì„ ìŠê²Œ í•œ ê²ƒì´ ì•„ë‹Œê°€ í•˜ëŠ” ì˜ê²¬ë„ ìˆë‹¤.\",\n",
      "    \"question\": \"ë°”ê·¸ë„ˆëŠ” ê´´í…Œì˜ íŒŒìš°ìŠ¤íŠ¸ë¥¼ ì½ê³  ë¬´ì—‡ì„ ì“°ê³ ì í–ˆëŠ”ê°€?\",\n",
      "    \"answers\": {\n",
      "        \"text\": [\n",
      "            \"êµí–¥ê³¡\"\n",
      "        ],\n",
      "        \"answer_start\": [\n",
      "            54\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(dataset[\"train\"][0], ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cuvzgR2fC3-C"
   },
   "source": [
    "## 4. í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ì ì¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5mFZO1ZmAnr"
   },
   "source": [
    "`transformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poX7Xe7pEOso",
    "outputId": "cc737986-a986-4e65-a0fa-68b92b03753f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (4.48.3)\n",
      "Requirement already satisfied: filelock in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo6UslWcmIpO"
   },
   "source": [
    "ê¸°ë³¸ ëª¨ë¸ `distilbert-base-multilingual-cased`ë¥¼ ì§€ì •í•˜ê³  `DistilBertTokenizerFast` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í¬ë‚˜ì´ì €ë¥¼, `DistilBertForQuestionAnswering` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì ì¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zADW5Gsu-Gb",
    "outputId": "c9740f3f-c8cf-43cc-aae3-587b9d282916"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 13:06:37.571016: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-07 13:06:37.578499: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743998797.586394 2426081 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743998797.588796 2426081 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743998797.595986 2426081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743998797.595993 2426081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743998797.595994 2426081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743998797.595995 2426081 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-07 13:06:37.598619: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
    "\n",
    "# Load tokenizer and model\n",
    "base_model_name = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(base_model_name)\n",
    "model = DistilBertForQuestionAnswering.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2H3lSaUFL81"
   },
   "source": [
    "## 5. í† í¬ë‚˜ì´ì € í…ŒìŠ¤íŠ¸\n",
    "\n",
    "í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ ê³¼ì •ì— ëŒ€í•œ ì´í•´ë¥¼ ë•ê¸° ìœ„í•˜ì—¬ ê°„ë‹¨í•œ ì˜ˆì œë¡œ í† í¬ë‚˜ì´ì €ë¥¼ í…ŒìŠ¤íŠ¸í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O4PgV3IaEoVt"
   },
   "outputs": [],
   "source": [
    "questions = [\"ê³ ì–‘ì´ê°€ ì–´ë””ì— ì•‰ìŠµë‹ˆê¹Œ?\"]\n",
    "contexts = [\"ê³ ì–‘ì´ê°€ ì˜ìì— ì•‰ìŠµë‹ˆë‹¤.\"]\n",
    "\n",
    "inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=25,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbXDTqCZpKrg"
   },
   "source": [
    "í† í¬ë‚˜ì´ì € ì‹¤í–‰ ê²°ê³¼ì¸ `inputs`ì˜ ìœ í˜•ê³¼ í‚¤ í•­ëª©ë“¤ì„ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrIII6NIpRwa",
    "outputId": "06fffcfa-8cc2-4220-f607-437214d7a379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "dict_keys(['input_ids', 'attention_mask', 'offset_mapping'])\n"
     ]
    }
   ],
   "source": [
    "print(type(inputs))\n",
    "print(inputs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HioUORAqFN-"
   },
   "source": [
    "ê°ê°ì˜ í‚¤ í•­ëª©ë“¤ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ì¶œë ¥í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYS25q6opxHd",
    "outputId": "493b2f82-85ef-4441-9ec6-86d2ffa06a78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [[101, 8888, 37114, 57362, 9546, 48446, 10530, 9522, 119081, 25503, 118671, 136, 102, 8888, 37114, 57362, 9637, 13764, 10530, 9522, 119081, 48345, 119, 102, 0]]\n",
      "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]\n",
      "offset_mapping: [[(0, 0), (0, 1), (1, 2), (2, 4), (5, 6), (6, 7), (7, 8), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (0, 0), (0, 1), (1, 2), (2, 4), (5, 6), (6, 7), (7, 8), (9, 10), (10, 11), (11, 13), (13, 14), (0, 0), (0, 0)]]\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids: \", end=\"\")\n",
    "print(inputs[\"input_ids\"])\n",
    "\n",
    "print(\"attention_mask: \", end=\"\")\n",
    "print(inputs[\"attention_mask\"])\n",
    "\n",
    "print(\"offset_mapping: \", end=\"\")\n",
    "print(inputs[\"offset_mapping\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a81S7uWiqPpj"
   },
   "source": [
    "`input_ids`ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ í† í° ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ ë³´ë©´ ê°ê°ì˜ í‚¤ í•­ëª©ë“¤ì˜ ì˜ë¯¸ë¥¼ ì¢€ ë” ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l5UmQXnyFwhf",
    "outputId": "2beee27a-a4ff-4b36-e4bb-912bd3a9aa19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_strs: ['[CLS]', 'ê³ ', '##ì–‘', '##ì´ê°€', 'ì–´', '##ë””', '##ì—', 'ì•‰', '##ìŠµ', '##ë‹ˆ', '##ê¹Œ', '?', '[SEP]', 'ê³ ', '##ì–‘', '##ì´ê°€', 'ì˜', '##ì', '##ì—', 'ì•‰', '##ìŠµ', '##ë‹ˆë‹¤', '.', '[SEP]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "token_strs = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "print(\"token_strs: \", end=\"\")\n",
    "print(token_strs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZB_TDAzq7fz"
   },
   "source": [
    "`token_strs`ì„ ì‚´í´ ë³´ë©´ ë‹µë³€ì— í•´ë‹¹í•˜ëŠ” í† í° 'bench'ì˜ ì‹œì‘ ìœ„ì¹˜ì™€ ë ìœ„ì¹˜ê°€  ê°ê° 11ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EI6-4E_lK9UN"
   },
   "source": [
    "## 6. í† í° ë°°ì—´ì—ì„œ ë‹µë³€ì˜ ì‹œì‘ í† í° ìœ„ì¹˜ì™€ ë í† í° ìœ„ì¹˜ ì°¾ëŠ” ë°©ë²•\n",
    "\n",
    "í† í¬ë‚˜ì´ì € ì¶œë ¥ ê²°ê³¼ ì¤‘ì—ì„œ í™œìš©í•´ì•¼ í•  ì •ë³´ê°€ í•˜ë‚˜ ë” ìˆëŠ”ë° ê·¸ê²ƒì€ sequence_idsì…ë‹ˆë‹¤. ì´ê²ƒìœ¼ë¡œë¶€í„° ê°ê°ì˜ í† í°ì´ í† í¬ë‚˜ì´ì €ì— ì…ë ¥í•œ ë¬¸ìì—´ë“¤ ì¤‘ì—ì„œ ëª‡ ë²ˆì§¸ ë¬¸ìì—´ì— í•´ë‹¹í•˜ëŠ” ê²ƒì¸ì§€ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "* sequence_idsì˜ ê°’ì´ 0ì´ë©´ í† í¬ë‚˜ì´ì €ì˜ ì²«ë²ˆì§¸ ì¸ì(`questions`)ë¡œë¶€í„° ì˜¨ í† í°\n",
    "* sequence_idsì˜ ê°’ì´ 1ì´ë©´ í† í¬ë‚˜ì´ì €ì˜ ë‘ë²ˆì§¸ ì¸ì(`contexts`)ë¡œë¶€í„° ì˜¨ í† í°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GizydGWep4-2",
    "outputId": "8e755e94-b887-4471-c045-739a55f6c4d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(sequence_ids): <class 'method'>\n",
      "sequence_ids(0): [None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None, None]\n"
     ]
    }
   ],
   "source": [
    "print(\"type(sequence_ids): \", end=\"\")\n",
    "print(type(inputs.sequence_ids))\n",
    "\n",
    "print(\"sequence_ids(0): \", end=\"\")\n",
    "print(inputs.sequence_ids(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKCMy2scrHxf"
   },
   "source": [
    "ì´ì œ í† í° ë°°ì—´ì—ì„œ ë‹µë³€ì˜ ì‹œì‘ í† í° ìœ„ì¹˜ì™€ ë í† í° ìœ„ì¹˜ë¥¼ ì°¾ê¸° ìœ„í•´ í•„ìš”ë¡œ í•˜ëŠ” ì •ë³´ëŠ” ëª¨ë‘ í™•ë³´í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "* `inputs.sequence_ids(0): [None, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, None, None]`\n",
    "* `inputs[\"offset_mapping\"][0]: [(0, 0), (0, 5), (6, 10), (11, 14), (15, 19), (19, 20), (0, 0), (0, 3), (4, 8), (9, 11), (12, 13), (14, 19), (19, 20), (0, 0), (0, 0)]`\n",
    "* `start_char: 14`\n",
    "* `end_char: 19`\n",
    "\n",
    "ì´ ì •ë³´ë“¤ì„ í™œìš©í•˜ì—¬ ë‹µë³€ì˜ ìœ„ì¹˜ë¥¼ ê¸°ê³„ì ìœ¼ë¡œ ì°¾ëŠ” ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. sequence_idsì—ì„œ contextì— í•´ë‹¹í•˜ëŠ” í† í°ë“¤ ìœ„ì¹˜ ì°¾ê¸°\n",
    "  1. ê°’ì´ 1ì¸ ìš”ì†Œë“¤ ì¤‘ì—ì„œ ì²«ë²ˆì§¸ ê²ƒì˜ ìœ„ì¹˜: `7`\n",
    "  2. ê°’ì´ 1ì¸ ìš”ì†Œë“¤ ì¤‘ì—ì„œ ë§ˆì§€ë§‰ ê²ƒì˜ ìœ„ì¹˜: `12`\n",
    "2. offset_mappingì—ì„œ contextì— í•´ë‹¹í•˜ëŠ” í† í°ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ë‹µë³€ì˜ ì‹œì‘ ìœ„ì¹˜ì™€ ë ìœ„ì¹˜ì— í•´ë‹¹í•˜ëŠ” í† í° ìœ„ì¹˜ ì°¾ê¸°\n",
    "  1. `start_char` ê°’ì¸ 14ë¥¼ í¬í•¨í•˜ëŠ” offset_mapping íŠœí”Œì˜ ìœ„ì¹˜: `11`\n",
    "  2. `end_char` ê°’ì¸ 19ë¥¼ í¬í•¨í•˜ëŠ” offset_mapping íŠœí”Œì˜ ìœ„ì¹˜: `11`\n",
    "\n",
    "ë‹µë³€ì˜ ì‹œì‘ í† í° ìœ„ì¹˜ì™€ ë í† í°ì˜ ìœ„ì¹˜ê°€ í›ˆë ¨ ë°ì´í„°ì—ì„œ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì •ë‹µìœ¼ë¡œ ê°„ì£¼ë˜ëŠ” ê°’ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiXcWOvnTjn8"
   },
   "source": [
    "## 7. í›ˆë ¨ ë°ì´í„° ìƒì„±\n",
    "\n",
    "ì›ë³¸ ë°ì´í„°ì…‹ì—ì„œ ê°œë³„ ë°ì´í„° í•­ëª©ì€ ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G8hKTEhUwnct"
   },
   "outputs": [],
   "source": [
    "examples_like_squad = [\n",
    "    {\n",
    "        \"context\": \"ê³ ì–‘ì´ê°€ ì˜ìì— ì•‰ìŠµë‹ˆë‹¤.\",\n",
    "        \"question\": \"ê³ ì–‘ì´ê°€ ì–´ë””ì— ì•‰ìŠµë‹ˆê¹Œ?\",\n",
    "        \"answers\": {\n",
    "            \"text\": [\"ì˜ì\"],\n",
    "            \"answer_start\": [5]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf61oon22l5y"
   },
   "source": [
    "í›ˆë ¨ìš© ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ì€ êµ¬ì¡°ì˜ ë°ì´í„°ë¥¼ ì¸ìë¡œ ë°›ì•„ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LdjcAFdP0PpC"
   },
   "outputs": [],
   "source": [
    "examples_for_preprocess = {\n",
    "    \"context\": [\"ê³ ì–‘ì´ê°€ ì˜ìì— ì•‰ìŠµë‹ˆë‹¤.\"],\n",
    "    \"question\": [\"ê³ ì–‘ì´ê°€ ì–´ë””ì— ì•‰ìŠµë‹ˆê¹Œ?\"],\n",
    "    \"answers\": [\n",
    "        {\n",
    "            \"text\": [\"ì˜ì\"],\n",
    "            \"answer_start\": [5]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7VZuSSI3hyP"
   },
   "source": [
    "ë°ì´í„°ì…‹ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ í† í° ë°°ì—´ë¡œ ë§Œë“¤ê³  ë‹µë³€ì˜ ì‹œì‘ í† í° ìœ„ì¹˜ì™€ ë í† í°ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì„œ í›ˆë ¨ìš© ë°ì´í„°ë¥¼ ë§Œë“œëŠ” ì „ì²˜ë¦¬ í•¨ìˆ˜ì˜ êµ¬í˜„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "2r1EwGLZvFAt"
   },
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def preprocess_function(examples, max_length=384):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        context_start = sequence_ids.index(1)\n",
    "        context_end = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offsets[context_start][0] > end_char or offsets[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise find the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offsets[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offsets[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGFucTtw3-Aq"
   },
   "source": [
    "ìœ„ì—ì„œ ì¤€ë¹„í•œ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ ë´…ë‹ˆë‹¤. í™”ë©´ í‘œì‹œì˜ í¸ì˜ë¥¼ ìœ„í•˜ì—¬ `max_length`ì˜ ê°’ì„ 15ë¡œ ì§€ì •í•˜ì˜€ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHGyiwPaUKZU",
    "outputId": "7bb63427-7e0f-4993-c6ef-f788a9779ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [[101, 8888, 37114, 57362, 9546, 48446, 10530, 9522, 119081, 25503, 118671, 136, 102, 8888, 37114, 57362, 9637, 13764, 10530, 9522, 119081, 48345, 119, 102, 0]]\n",
      "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]\n",
      "start_positions: [16]\n",
      "end_positions: [17]\n"
     ]
    }
   ],
   "source": [
    "results = preprocess_function(examples_for_preprocess, max_length=25)\n",
    "print(f'input_ids: {results[\"input_ids\"]}')\n",
    "print(f'attention_mask: {results[\"attention_mask\"]}')\n",
    "print(f'start_positions: {results[\"start_positions\"]}')\n",
    "print(f'end_positions: {results[\"end_positions\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d2345c97cf9e4f4a9c1a1344c928fdf0",
      "a4088c8d15fb41efb56ca8295c7f25b5",
      "87df2842719045488595c9725e386297",
      "6de2a2c502be4e4fa4770ea0eb4fe94e",
      "85e055a4dcaf4131ad4cad24b5b2410c",
      "32fa3ff8af104c4d9f23ed652c721e20",
      "30d72eedc6714e21a7f200cb0abcfd33",
      "ed9c813e80fc43b096bda875f665b176",
      "1ade48e3bc6d4a46a86b599e87ea406b",
      "8eabe883b07b4d968dd2cd8bff9ca264",
      "6de4057a54f84d10a3dcc7e0535a86e5"
     ]
    },
    "id": "GqJYhmQOT4Vc",
    "outputId": "7ae35b34-aef5-463d-cb21-5aa9cd97a4bf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a700ee69dd42bbb7cc4917dba5f1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5774 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply preprocessing to the dataset\n",
    "tokenized_datasets = dataset.map(preprocess_function,\n",
    "                                 batched=True,\n",
    "                                 remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYA38CqSWOYM"
   },
   "source": [
    "## 8. ë¯¸ì„¸ì¡°ì • í›ˆë ¨\n",
    "\n",
    "ì´ì œ SQuAD ë°ì´í„°ì…‹ì„ ëŒ€ìƒìœ¼ë¡œ DistilBertForQuestionAnswering ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EZmfn1Afm36",
    "outputId": "77251fbf-6eb2-4883-d3ec-13a4e76b841a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: accelerate in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: filelock in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from accelerate) (0.26.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: requests in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wjeong/DevEnv/py312/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "jlTnf83-T_xf",
    "outputId": "472dbaf4-5e88-4834-cec6-147aa9e3b320"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjeong/DevEnv/py312/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/tmp/ipykernel_2426081/173197551.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11328' max='11328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11328/11328 14:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.951200</td>\n",
       "      <td>0.827501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.678300</td>\n",
       "      <td>0.725673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.514500</td>\n",
       "      <td>0.739571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./fine-tuned-distilbert-korquad/tokenizer_config.json',\n",
       " './fine-tuned-distilbert-korquad/special_tokens_map.json',\n",
       " './fine-tuned-distilbert-korquad/vocab.txt',\n",
       " './fine-tuned-distilbert-korquad/added_tokens.json',\n",
       " './fine-tuned-distilbert-korquad/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Train the model and save the results\n",
    "trainer.train()\n",
    "\n",
    "finetuned_model_path = \"./fine-tuned-distilbert-korquad\"\n",
    "model.save_pretrained(finetuned_model_path)\n",
    "tokenizer.save_pretrained(finetuned_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZdlfDhR5Lj-"
   },
   "source": [
    "## 9. ë¯¸ì„¸ì¡°ì • í›ˆë ¨ ëª¨ë¸ë¡œ ì§ˆì˜ì‘ë‹µ ìˆ˜í–‰\n",
    "\n",
    "ì§€ë¬¸ê³¼ ì§ˆë¬¸ì„ ì¸ìë¡œ ë°›ì•„ì„œ ë‹µë³€ì„ ì°¾ì•„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "JwbCfrNC5bAL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_answer(tokenizer, model, context, question):\n",
    "    inputs = tokenizer(question, context, return_tensors=\"pt\")\n",
    "    input_tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    print(f\"input_tokens: {input_tokens}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    answer_start_index = outputs.start_logits.argmax()\n",
    "    answer_end_index = outputs.end_logits.argmax()\n",
    "\n",
    "    predict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
    "    output_tokens = tokenizer.convert_ids_to_tokens(predict_answer_tokens)\n",
    "\n",
    "    return output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmJKDKhkYncw"
   },
   "source": [
    "ë¨¼ì € ì§ˆì˜ì‘ë‹µ í›ˆë ¨ì„ í•˜ì§€ ì•Šì€ ê¸°ë³¸ ëª¨ë¸ë¡œ ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•´ ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mTL_JdURYFCU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert/distilbert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tokens: ['[CLS]', 'ì² ', '##ìˆ˜ëŠ”', 'ì–´', '##ë””', '##ì—', 'ì‚½', '##ë‹ˆ', '##ê¹Œ', '?', '[SEP]', 'ì² ', '##ìˆ˜ëŠ”', 'ì„œìš¸', '##ì—', 'ì‚½', '##ë‹ˆë‹¤', '.', '[SEP]']\n",
      "answer by base model: ['?', '[SEP]', 'ì² ', '##ìˆ˜ëŠ”', 'ì„œìš¸', '##ì—', 'ì‚½']\n"
     ]
    }
   ],
   "source": [
    "test_context = \"ì² ìˆ˜ëŠ” ì„œìš¸ì— ì‚½ë‹ˆë‹¤.\"\n",
    "test_question = \"ì² ìˆ˜ëŠ” ì–´ë””ì— ì‚½ë‹ˆê¹Œ?\"\n",
    "\n",
    "base_tokenizer = DistilBertTokenizerFast.from_pretrained(base_model_name)\n",
    "base_model = DistilBertForQuestionAnswering.from_pretrained(base_model_name)\n",
    "\n",
    "test_output_tokens = predict_answer(base_tokenizer, base_model, test_context, test_question)\n",
    "print(f\"answer by base model: {test_output_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74uJn51vYvbU"
   },
   "source": [
    "ì´ì œ ì§ˆì˜ì‘ë‹µ ë°ì´í„°ì— ëŒ€í•˜ì—¬ ë¯¸ì„¸ì¡°ì • í›ˆë ¨ì„ ê±°ì¹œ ëª¨ë¸ë¡œ ë‹µë³€ì„ ì˜ˆì¸¡í•˜ê³  ê¸°ë³¸ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ì™€ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jbO3_1mPYbf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tokens: ['[CLS]', 'ì² ', '##ìˆ˜ëŠ”', 'ì–´', '##ë””', '##ì—', 'ì‚½', '##ë‹ˆ', '##ê¹Œ', '?', '[SEP]', 'ì² ', '##ìˆ˜ëŠ”', 'ì„œìš¸', '##ì—', 'ì‚½', '##ë‹ˆë‹¤', '.', '[SEP]']\n",
      "answer by finetuned model: ['ì„œìš¸']\n"
     ]
    }
   ],
   "source": [
    "finetuned_tokenizer = DistilBertTokenizerFast.from_pretrained(finetuned_model_path)\n",
    "finetuned_model = DistilBertForQuestionAnswering.from_pretrained(finetuned_model_path)\n",
    "\n",
    "test_output_tokens = predict_answer(finetuned_tokenizer, finetuned_model, test_context, test_question)\n",
    "print(f\"answer by finetuned model: {test_output_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹µë³€ì´ ê¸°ëŒ€í•œ ë°”ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZ3y78jzXbpSmLBC0mDN3f",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ade48e3bc6d4a46a86b599e87ea406b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30d72eedc6714e21a7f200cb0abcfd33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32fa3ff8af104c4d9f23ed652c721e20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6de2a2c502be4e4fa4770ea0eb4fe94e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8eabe883b07b4d968dd2cd8bff9ca264",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6de4057a54f84d10a3dcc7e0535a86e5",
      "value": "â€‡10570/10570â€‡[00:15&lt;00:00,â€‡788.93â€‡examples/s]"
     }
    },
    "6de4057a54f84d10a3dcc7e0535a86e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85e055a4dcaf4131ad4cad24b5b2410c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87df2842719045488595c9725e386297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed9c813e80fc43b096bda875f665b176",
      "max": 10570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ade48e3bc6d4a46a86b599e87ea406b",
      "value": 10570
     }
    },
    "8eabe883b07b4d968dd2cd8bff9ca264": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4088c8d15fb41efb56ca8295c7f25b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32fa3ff8af104c4d9f23ed652c721e20",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_30d72eedc6714e21a7f200cb0abcfd33",
      "value": "Map:â€‡100%"
     }
    },
    "d2345c97cf9e4f4a9c1a1344c928fdf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4088c8d15fb41efb56ca8295c7f25b5",
       "IPY_MODEL_87df2842719045488595c9725e386297",
       "IPY_MODEL_6de2a2c502be4e4fa4770ea0eb4fe94e"
      ],
      "layout": "IPY_MODEL_85e055a4dcaf4131ad4cad24b5b2410c"
     }
    },
    "ed9c813e80fc43b096bda875f665b176": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
