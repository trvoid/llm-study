{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/trvoid/llm-study/blob/main/bert/getting_started_with_distilbert_for_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cvu_6JOiK0j"
   },
   "source": [
    "# DistilBERT for MLM 시작하기 (한국어)\n",
    "\n",
    "**노트: distilbert-base-multilingual-cased를 기본 모델로 사용하였음**\n",
    "\n",
    "이 실습은 아래 문서의 내용을 토대로 진행하였습니다.\n",
    "\n",
    "* [2. 마스크 언어 모델(Masked Language Model) 미세조정](https://wikidocs.net/166833), Transformers (신경망 언어모델 라이브러리) 강좌\n",
    "* [Fine-tuning a masked language model](https://huggingface.co/learn/llm-course/en/chapter7/3), LLM Course in Hugging Face\n",
    "\n",
    "사용할 모델과 데이터셋은 다음과 같습니다.\n",
    "\n",
    "* [DistilBERT](distilbert/distilbert-base-multilingual-cased):기본 모델 (단어에 대한 단순 임베딩이 아니라 맥락을 고려한 임베딩 수행)\n",
    "* [DistilBertForMaskedLM](https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.DistilBertForMaskedLM): DistilBERT 모델에 마스크 언어 모델 층을 추가한 것으로서 마스크 언어 모델 미세조정 훈련을 위한 모델\n",
    "* [nsmc](https://huggingface.co/datasets/Blpeng/nsmc): 네이버 영화 리뷰 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이저 및 모델 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU 사용 가능 여부 확인 및 장치 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 14:47:22.392622: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 14:47:22.400811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744177642.409334 2911333 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744177642.411909 2911333 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744177642.419823 2911333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177642.419831 2911333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177642.419832 2911333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177642.419833 2911333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-09 14:47:22.422661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForMaskedLM\n",
    "\n",
    "model_checkpoint = \"distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = DistilBertForMaskedLM.from_pretrained(model_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 119547\n",
      "model device: cuda:0\n",
      "DistilBERT number of parameters: 135M\n",
      "BERT number of parameters: 110M\n"
     ]
    }
   ],
   "source": [
    "print(f\"vocab size: {len(tokenizer)}\")\n",
    "print(f\"model device: {next(model.parameters()).device}\")\n",
    "distilbert_num_parameters = model.num_parameters() / 1_000_000\n",
    "print(f\"DistilBERT number of parameters: {round(distilbert_num_parameters)}M\")\n",
    "print(f\"BERT number of parameters: 110M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: tensor([   101,   9061, 119309,  11102,   8964,  11882,   9874, 119099,  11018,\n",
      "           103,   9637,   9248,  37004,    119,    102])\n",
      "len(input_ids): 15\n",
      "token_strs: ['[CLS]', '달', '##콤', '##한', '꿀', '##과', '톡', '##쏘', '##는', '[MASK]', '의', '만', '##남', '.', '[SEP]']\n",
      "decoded_text: [CLS] 달콤한 꿀과 톡쏘는 [MASK] 의 만남. [SEP]\n"
     ]
    }
   ],
   "source": [
    "#text = \"달콤한 꿀과 톡쏘는 칠리의 만남.\"\n",
    "text = \"달콤한 꿀과 톡쏘는 [MASK]의 만남.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=14, padding=\"max_length\")\n",
    "print(f\"input_ids: {inputs[\"input_ids\"][0]}\")\n",
    "print(f\"len(input_ids): {len(inputs[\"input_ids\"][0])}\")\n",
    "\n",
    "token_strs = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "print(f\"token_strs: {token_strs}\")\n",
    "\n",
    "decoded_text = tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "print(f\"decoded_text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> 달콤한 꿀과 톡쏘는 단의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 수의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 이의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 유의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 불의 만남.'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_topk_for_masked(tokenizer, model, text, topk=5):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items() if isinstance(v, torch.Tensor)}\n",
    "\n",
    "    token_logits = model(**inputs).logits\n",
    "    #print(token_logits.shape)\n",
    "    \n",
    "    # [MASK]의 위치를 찾고, 해당 logits을 추출합니다.\n",
    "    #print(torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id))\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "    #print(mask_token_index)\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    #print(mask_token_logits)\n",
    "    \n",
    "    # 가장 큰 logits값을 가지는 [MASK] 후보를 선택합니다.\n",
    "    top_5_tokens = torch.topk(mask_token_logits, topk, dim=1).indices[0].tolist()\n",
    "    \n",
    "    return top_5_tokens\n",
    "\n",
    "topk_tokens = find_topk_for_masked(tokenizer, model, text, 5)\n",
    "for token in topk_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 150000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"nsmc\"\n",
    "nsmc_dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "print(nsmc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> Review: For Carl.칼 세이건으로 시작해서 칼 세이건으로 끝난다.'\n",
      "'>>> Label: 1'\n",
      "\n",
      "'>>> Review: 모든 면에서 너무 좋고, 특히 동양적이고'\n",
      "'>>> Label: 1'\n",
      "\n",
      "'>>> Review: 달콤한 꿀과 톡쏘는 칠리의 만남'\n",
      "'>>> Label: 1'\n"
     ]
    }
   ],
   "source": [
    "sample = nsmc_dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\"\\n'>>> Review: {row['document']}'\")\n",
    "    print(f\"'>>> Label: {row['label']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"document\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 8924, 118627, 10892, 10005, 118901, 11102, 42428, 119147, 119081, 48345, 119, 102], [101, 9663, 11018, 8924, 42428, 11513, 9765, 38631, 23665, 9523, 119081, 48345, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'word_ids': [[None, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, None], [None, 0, 0, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, None]]}\n",
      "['[CLS]', '저', '##는', '그', '영화', '##를', '추', '##천', '##하지', '않', '##습', '##니다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "test_examples = {\n",
    "    \"document\": [\"그것은 훌륭한 영화였습니다.\", \"저는 그 영화를 추천하지 않습니다.\"]\n",
    "}\n",
    "test_result = tokenize_function(test_examples)\n",
    "print(test_result)\n",
    "token_strs = tokenizer.convert_ids_to_tokens(test_result[\"input_ids\"][1])\n",
    "print(token_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 150000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 빠른 멀티스레딩을 작동시키기 위해서, batched=True를 지정합니다.\n",
    "tokenized_datasets = nsmc_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"id\", \"document\", \"label\"]\n",
    ")\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_max_length: 512\n"
     ]
    }
   ],
   "source": [
    "print(f\"model_max_length: {tokenizer.model_max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk_size = 128\n",
    "chunk_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 length: 17\n",
      "Review 1 length: 31\n",
      "Review 2 length: 3\n"
     ]
    }
   ],
   "source": [
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"Review {idx} length: {len(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated reviews length: 51\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"Concatenated reviews length: {total_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 51'\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # 모든 텍스트들을 결합한다.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # 결합된 텍스트들에 대한 길이를 구한다.\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # `chunk_size`보다 작은 경우 마지막 청크를 삭제\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # max_len 길이를 가지는 chunk 단위로 슬라이스\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # 새로운 레이블 컬럼을 생성\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 25855\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 8643\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##도 아까움. [SEP] [CLS] 원작의 긴장감을 제대로 살려내지못했다. [SEP] [CLS] 별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지.. 정말 발로해도 그것보단 낫겟다 납치. 감금만반복반복.. 이드라마는 가족도없다 연기못하는사람만모엿네 [SEP] [CLS] 액션이 없는데도 재미 있는 몇안되는 영화 [SEP] [CLS] 왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나? [SEP]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##도 아까움. [SEP] [CLS] 원작의 긴장감을 제대로 살려내지못했다. [SEP] [CLS] 별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지.. 정말 발로해도 그것보단 낫겟다 납치. 감금만반복반복.. 이드라마는 가족도없다 연기못하는사람만모엿네 [SEP] [CLS] 액션이 없는데도 재미 있는 몇안되는 영화 [SEP] [CLS] 왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나? [SEP]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] 아 더빙.. 진짜 [MASK] [MASK]나네요 [MASK]소리 [SEP] [CLS] [UNK]... 포스터보고 초딩영 [MASK]줄.. [MASK] [MASK] 오버연기 [MASK]차Ժ볍 [MASK] 않구나 [SEP] [CLS] [UNK] [SEP] [CLS] 교도소 이야기구먼.. 솔직히 재미는 [MASK] [MASK]. 평점 조정 [SEP] [CLS] 사이몬 [MASK]그 [MASK] 익살 PS런 [MASK]기가 돋보였던 영화! 스파이더맨에서 늙어보이기만 했던 커 [MASK]틴 던스트가 너무나 [MASK] 이뻐보였다 [SEP] [CLS] 막 걸음마 [UNK] 3 [MASK]부터 [MASK]등학교 1학년생인 8살용粘화 [MASK] [UNK]. [MASK]. 별반개'\n",
      "\n",
      "'>>> ##도 아까움. [SEP] [CLS] 원 [MASK]의 agricultural장감을 제대로 살려내지 [MASK]했다. [SEP] [CLS] 별 [MASK]개도 아깝다 [MASK]나온다 이응경 길용우 연기생활이몇년 [MASK] [MASK].. 정말 발로 [MASK]도 [MASK]것보단 낫겟다 납치. 감 [MASK]만반복반복.. 이드라마 [MASK] 가족도없다 연기못하는사람만모엿네 [SEP] [CLS] 액 [MASK]이 없는데 [MASK] 재 [MASK] 있는 [MASK]안되는 영화 [SEP] [CLS] 왜케 평점 [MASK] 낮은건데? 꽤 볼만한데.. 헐리우 [MASK] [MASK] 화 [MASK]함에만 너무 길들여져 있나? [SEP]'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # 단어와 해당 토큰 인덱스 간의 map 생성\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # 무작위로 단어 마스킹\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "\n",
    "    return default_data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] 아 더빙 [MASK]. [MASK] [MASK] 짜증나네요 목소리 [SEP] [CLS] [UNK]... 포스터보고 [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [MASK]. 오버연기조차 가볍지 않구나 [SEP] [CLS] [UNK] [SEP] [CLS] 교도소 이야기구먼 [MASK]. 솔직히 [MASK] [MASK] [MASK] [MASK].. 평점 [MASK] [MASK] [SEP] [CLS] 사이몬페그의 익살스런 연기가 [MASK] [MASK] [MASK] 영화! 스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다 [SEP] [CLS] 막 걸음마 [UNK] 3세부터 [MASK] [MASK] 1학년생인 8살용영화. [UNK]... 별반개'\n",
      "\n",
      "'>>> ##도 아까움. [SEP] [CLS] [MASK] [MASK] [MASK] 긴장감을 제대로 [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP] [CLS] [MASK] 반개도 아깝다 욕나온다 이응경 길용우 [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [MASK] 정말 [MASK] [MASK] [MASK] [MASK] 그것보단 낫겟다 납치. 감금만반복반복.. 이드라마는 가족도없다 연기못하는사람만모엿네 [SEP] [CLS] 액션이 없는데도 재미 [MASK] 몇안되는 영화 [SEP] [CLS] [MASK] [MASK] 평점이 낮은건데? [MASK] 볼만한데.. [MASK] [MASK] [MASK] [MASK] [MASK] 화려함에만 너무 [MASK] [MASK] [MASK] [MASK] 있나? [SEP]'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터 개수와 테스트 데이터 개수를 지정하여 샘플링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 23269\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 2586\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_size = 10_000\n",
    "#test_size = int(0.1 * train_size)\n",
    "train_size = None\n",
    "test_size = 0.1\n",
    "\n",
    "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미세조정 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjeong/DevEnv/py312/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-nsmc\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 274.00\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1092' max='1092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1092/1092 02:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.604100</td>\n",
       "      <td>3.070170</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.107300</td>\n",
       "      <td>2.869706</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.981400</td>\n",
       "      <td>2.876446</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "finetuned_model_path = \"./fine-tuned-distilbert-nsmc-mlm\"\n",
    "tokenizer.save_pretrained(finetuned_model_path)\n",
    "model.save_pretrained(finetuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 17.04\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'input text: 달콤한 꿀과 톡쏘는 [MASK]의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 영화의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 맛의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 것의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 잔의 만남.'\n",
      "'>>> 달콤한 꿀과 톡쏘는 한의 만남.'\n"
     ]
    }
   ],
   "source": [
    "print(f\"'input text: {text}'\")\n",
    "topk_tokens = find_topk_for_masked(tokenizer, model, text, topk=5)\n",
    "for token in topk_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZ3y78jzXbpSmLBC0mDN3f",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ade48e3bc6d4a46a86b599e87ea406b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30d72eedc6714e21a7f200cb0abcfd33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32fa3ff8af104c4d9f23ed652c721e20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6de2a2c502be4e4fa4770ea0eb4fe94e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8eabe883b07b4d968dd2cd8bff9ca264",
      "placeholder": "​",
      "style": "IPY_MODEL_6de4057a54f84d10a3dcc7e0535a86e5",
      "value": " 10570/10570 [00:15&lt;00:00, 788.93 examples/s]"
     }
    },
    "6de4057a54f84d10a3dcc7e0535a86e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85e055a4dcaf4131ad4cad24b5b2410c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87df2842719045488595c9725e386297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed9c813e80fc43b096bda875f665b176",
      "max": 10570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ade48e3bc6d4a46a86b599e87ea406b",
      "value": 10570
     }
    },
    "8eabe883b07b4d968dd2cd8bff9ca264": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4088c8d15fb41efb56ca8295c7f25b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32fa3ff8af104c4d9f23ed652c721e20",
      "placeholder": "​",
      "style": "IPY_MODEL_30d72eedc6714e21a7f200cb0abcfd33",
      "value": "Map: 100%"
     }
    },
    "d2345c97cf9e4f4a9c1a1344c928fdf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4088c8d15fb41efb56ca8295c7f25b5",
       "IPY_MODEL_87df2842719045488595c9725e386297",
       "IPY_MODEL_6de2a2c502be4e4fa4770ea0eb4fe94e"
      ],
      "layout": "IPY_MODEL_85e055a4dcaf4131ad4cad24b5b2410c"
     }
    },
    "ed9c813e80fc43b096bda875f665b176": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
