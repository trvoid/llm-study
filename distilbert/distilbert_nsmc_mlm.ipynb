{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/trvoid/llm-study/blob/main/bert/getting_started_with_distilbert_for_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cvu_6JOiK0j"
   },
   "source": [
    "# DistilBERT for MLM ÏãúÏûëÌïòÍ∏∞ (ÌïúÍµ≠Ïñ¥)\n",
    "\n",
    "**ÎÖ∏Ìä∏: distilbert-base-multilingual-casedÎ•º Í∏∞Î≥∏ Î™®Îç∏Î°ú ÏÇ¨Ïö©ÌïòÏòÄÏùå**\n",
    "\n",
    "Ïù¥ Ïã§ÏäµÏùÄ ÏïÑÎûò Î¨∏ÏÑúÏùò ÎÇ¥Ïö©ÏùÑ ÌÜ†ÎåÄÎ°ú ÏßÑÌñâÌïòÏòÄÏäµÎãàÎã§.\n",
    "\n",
    "* [2. ÎßàÏä§ÌÅ¨ Ïñ∏Ïñ¥ Î™®Îç∏(Masked Language Model) ÎØ∏ÏÑ∏Ï°∞Ï†ï](https://wikidocs.net/166833), Transformers (Ïã†Í≤ΩÎßù Ïñ∏Ïñ¥Î™®Îç∏ ÎùºÏù¥Î∏åÎü¨Î¶¨) Í∞ïÏ¢å\n",
    "* [Fine-tuning a masked language model](https://huggingface.co/learn/llm-course/en/chapter7/3), LLM Course in Hugging Face\n",
    "\n",
    "ÏÇ¨Ïö©Ìï† Î™®Îç∏Í≥º Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
    "\n",
    "* [DistilBERT](distilbert/distilbert-base-multilingual-cased):Í∏∞Î≥∏ Î™®Îç∏ (Îã®Ïñ¥Ïóê ÎåÄÌïú Îã®Ïàú ÏûÑÎ≤†Îî©Ïù¥ ÏïÑÎãàÎùº Îß•ÎùΩÏùÑ Í≥†Î†§Ìïú ÏûÑÎ≤†Îî© ÏàòÌñâ)\n",
    "* [DistilBertForMaskedLM](https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.DistilBertForMaskedLM): DistilBERT Î™®Îç∏Ïóê ÎßàÏä§ÌÅ¨ Ïñ∏Ïñ¥ Î™®Îç∏ Ï∏µÏùÑ Ï∂îÍ∞ÄÌïú Í≤ÉÏúºÎ°úÏÑú ÎßàÏä§ÌÅ¨ Ïñ∏Ïñ¥ Î™®Îç∏ ÎØ∏ÏÑ∏Ï°∞Ï†ï ÌõàÎ†®ÏùÑ ÏúÑÌïú Î™®Îç∏\n",
    "* [nsmc](https://huggingface.co/datasets/Blpeng/nsmc): ÎÑ§Ïù¥Î≤Ñ ÏòÅÌôî Î¶¨Î∑∞ Îç∞Ïù¥ÌÑ∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î∞è Î™®Îç∏ Ï†ÅÏû¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏ Î∞è Ïû•Ïπò ÏÑ§Ï†ï\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 14:47:22.392622: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 14:47:22.400811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744177642.409334 2911333 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744177642.411909 2911333 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744177642.419823 2911333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177642.419831 2911333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177642.419832 2911333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744177642.419833 2911333 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-09 14:47:22.422661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForMaskedLM\n",
    "\n",
    "model_checkpoint = \"distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = DistilBertForMaskedLM.from_pretrained(model_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 119547\n",
      "model device: cuda:0\n",
      "DistilBERT number of parameters: 135M\n",
      "BERT number of parameters: 110M\n"
     ]
    }
   ],
   "source": [
    "print(f\"vocab size: {len(tokenizer)}\")\n",
    "print(f\"model device: {next(model.parameters()).device}\")\n",
    "distilbert_num_parameters = model.num_parameters() / 1_000_000\n",
    "print(f\"DistilBERT number of parameters: {round(distilbert_num_parameters)}M\")\n",
    "print(f\"BERT number of parameters: 110M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: tensor([   101,   9061, 119309,  11102,   8964,  11882,   9874, 119099,  11018,\n",
      "           103,   9637,   9248,  37004,    119,    102])\n",
      "len(input_ids): 15\n",
      "token_strs: ['[CLS]', 'Îã¨', '##ÏΩ§', '##Ìïú', 'ÍøÄ', '##Í≥º', 'ÌÜ°', '##Ïèò', '##Îäî', '[MASK]', 'Ïùò', 'Îßå', '##ÎÇ®', '.', '[SEP]']\n",
      "decoded_text: [CLS] Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî [MASK] Ïùò ÎßåÎÇ®. [SEP]\n"
     ]
    }
   ],
   "source": [
    "#text = \"Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî Ïπ†Î¶¨Ïùò ÎßåÎÇ®.\"\n",
    "text = \"Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî [MASK]Ïùò ÎßåÎÇ®.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=14, padding=\"max_length\")\n",
    "print(f\"input_ids: {inputs[\"input_ids\"][0]}\")\n",
    "print(f\"len(input_ids): {len(inputs[\"input_ids\"][0])}\")\n",
    "\n",
    "token_strs = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "print(f\"token_strs: {token_strs}\")\n",
    "\n",
    "decoded_text = tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "print(f\"decoded_text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî Îã®Ïùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî ÏàòÏùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî Ïù¥Ïùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî Ïú†Ïùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî Î∂àÏùò ÎßåÎÇ®.'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_topk_for_masked(tokenizer, model, text, topk=5):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items() if isinstance(v, torch.Tensor)}\n",
    "\n",
    "    token_logits = model(**inputs).logits\n",
    "    #print(token_logits.shape)\n",
    "    \n",
    "    # [MASK]Ïùò ÏúÑÏπòÎ•º Ï∞æÍ≥†, Ìï¥Îãπ logitsÏùÑ Ï∂îÏ∂úÌï©ÎãàÎã§.\n",
    "    #print(torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id))\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "    #print(mask_token_index)\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    #print(mask_token_logits)\n",
    "    \n",
    "    # Í∞ÄÏû• ÌÅ∞ logitsÍ∞íÏùÑ Í∞ÄÏßÄÎäî [MASK] ÌõÑÎ≥¥Î•º ÏÑ†ÌÉùÌï©ÎãàÎã§.\n",
    "    top_5_tokens = torch.topk(mask_token_logits, topk, dim=1).indices[0].tolist()\n",
    "    \n",
    "    return top_5_tokens\n",
    "\n",
    "topk_tokens = find_topk_for_masked(tokenizer, model, text, 5)\n",
    "for token in topk_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ÅÏû¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 150000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"nsmc\"\n",
    "nsmc_dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "print(nsmc_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> Review: For Carl.Ïπº ÏÑ∏Ïù¥Í±¥ÏúºÎ°ú ÏãúÏûëÌï¥ÏÑú Ïπº ÏÑ∏Ïù¥Í±¥ÏúºÎ°ú ÎÅùÎÇúÎã§.'\n",
      "'>>> Label: 1'\n",
      "\n",
      "'>>> Review: Î™®Îì† Î©¥ÏóêÏÑú ÎÑàÎ¨¥ Ï¢ãÍ≥†, ÌäπÌûà ÎèôÏñëÏ†ÅÏù¥Í≥†'\n",
      "'>>> Label: 1'\n",
      "\n",
      "'>>> Review: Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî Ïπ†Î¶¨Ïùò ÎßåÎÇ®'\n",
      "'>>> Label: 1'\n"
     ]
    }
   ],
   "source": [
    "sample = nsmc_dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\"\\n'>>> Review: {row['document']}'\")\n",
    "    print(f\"'>>> Label: {row['label']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"document\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 8924, 118627, 10892, 10005, 118901, 11102, 42428, 119147, 119081, 48345, 119, 102], [101, 9663, 11018, 8924, 42428, 11513, 9765, 38631, 23665, 9523, 119081, 48345, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'word_ids': [[None, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, None], [None, 0, 0, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, None]]}\n",
      "['[CLS]', 'Ï†Ä', '##Îäî', 'Í∑∏', 'ÏòÅÌôî', '##Î•º', 'Ï∂î', '##Ï≤ú', '##ÌïòÏßÄ', 'Ïïä', '##Ïäµ', '##ÎãàÎã§', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "test_examples = {\n",
    "    \"document\": [\"Í∑∏Í≤ÉÏùÄ ÌõåÎ•≠Ìïú ÏòÅÌôîÏòÄÏäµÎãàÎã§.\", \"Ï†ÄÎäî Í∑∏ ÏòÅÌôîÎ•º Ï∂îÏ≤úÌïòÏßÄ ÏïäÏäµÎãàÎã§.\"]\n",
    "}\n",
    "test_result = tokenize_function(test_examples)\n",
    "print(test_result)\n",
    "token_strs = tokenizer.convert_ids_to_tokens(test_result[\"input_ids\"][1])\n",
    "print(token_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 150000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Îπ†Î•∏ Î©ÄÌã∞Ïä§Î†àÎî©ÏùÑ ÏûëÎèôÏãúÌÇ§Í∏∞ ÏúÑÌï¥ÏÑú, batched=TrueÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n",
    "tokenized_datasets = nsmc_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"id\", \"document\", \"label\"]\n",
    ")\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_max_length: 512\n"
     ]
    }
   ],
   "source": [
    "print(f\"model_max_length: {tokenizer.model_max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk_size = 128\n",
    "chunk_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 length: 17\n",
      "Review 1 length: 31\n",
      "Review 2 length: 3\n"
     ]
    }
   ],
   "source": [
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"Review {idx} length: {len(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated reviews length: 51\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"Concatenated reviews length: {total_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 51'\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Î™®Îì† ÌÖçÏä§Ìä∏Îì§ÏùÑ Í≤∞Ìï©ÌïúÎã§.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Í≤∞Ìï©Îêú ÌÖçÏä§Ìä∏Îì§Ïóê ÎåÄÌïú Í∏∏Ïù¥Î•º Íµ¨ÌïúÎã§.\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # `chunk_size`Î≥¥Îã§ ÏûëÏùÄ Í≤ΩÏö∞ ÎßàÏßÄÎßâ Ï≤≠ÌÅ¨Î•º ÏÇ≠Ï†ú\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # max_len Í∏∏Ïù¥Î•º Í∞ÄÏßÄÎäî chunk Îã®ÏúÑÎ°ú Ïä¨ÎùºÏù¥Ïä§\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # ÏÉàÎ°úÏö¥ Î†àÏù¥Î∏î Ïª¨ÎüºÏùÑ ÏÉùÏÑ±\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 25855\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 8643\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##ÎèÑ ÏïÑÍπåÏõÄ. [SEP] [CLS] ÏõêÏûëÏùò Í∏¥Ïû•Í∞êÏùÑ Ï†úÎåÄÎ°ú ÏÇ¥Î†§ÎÇ¥ÏßÄÎ™ªÌñàÎã§. [SEP] [CLS] Î≥Ñ Î∞òÍ∞úÎèÑ ÏïÑÍπùÎã§ ÏöïÎÇòÏò®Îã§ Ïù¥ÏùëÍ≤Ω Í∏∏Ïö©Ïö∞ Ïó∞Í∏∞ÏÉùÌôúÏù¥Î™áÎÖÑÏù∏ÏßÄ.. Ï†ïÎßê Î∞úÎ°úÌï¥ÎèÑ Í∑∏Í≤ÉÎ≥¥Îã® ÎÇ´Í≤üÎã§ ÎÇ©Ïπò. Í∞êÍ∏àÎßåÎ∞òÎ≥µÎ∞òÎ≥µ.. Ïù¥ÎìúÎùºÎßàÎäî Í∞ÄÏ°±ÎèÑÏóÜÎã§ Ïó∞Í∏∞Î™ªÌïòÎäîÏÇ¨ÎûåÎßåÎ™®ÏóøÎÑ§ [SEP] [CLS] Ïï°ÏÖòÏù¥ ÏóÜÎäîÎç∞ÎèÑ Ïû¨ÎØ∏ ÏûàÎäî Î™áÏïàÎêòÎäî ÏòÅÌôî [SEP] [CLS] ÏôúÏºÄ ÌèâÏ†êÏù¥ ÎÇÆÏùÄÍ±¥Îç∞? ÍΩ§ Î≥ºÎßåÌïúÎç∞.. ÌóêÎ¶¨Ïö∞ÎìúÏãù ÌôîÎ†§Ìï®ÏóêÎßå ÎÑàÎ¨¥ Í∏∏Îì§Ïó¨Ï†∏ ÏûàÎÇò? [SEP]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##ÎèÑ ÏïÑÍπåÏõÄ. [SEP] [CLS] ÏõêÏûëÏùò Í∏¥Ïû•Í∞êÏùÑ Ï†úÎåÄÎ°ú ÏÇ¥Î†§ÎÇ¥ÏßÄÎ™ªÌñàÎã§. [SEP] [CLS] Î≥Ñ Î∞òÍ∞úÎèÑ ÏïÑÍπùÎã§ ÏöïÎÇòÏò®Îã§ Ïù¥ÏùëÍ≤Ω Í∏∏Ïö©Ïö∞ Ïó∞Í∏∞ÏÉùÌôúÏù¥Î™áÎÖÑÏù∏ÏßÄ.. Ï†ïÎßê Î∞úÎ°úÌï¥ÎèÑ Í∑∏Í≤ÉÎ≥¥Îã® ÎÇ´Í≤üÎã§ ÎÇ©Ïπò. Í∞êÍ∏àÎßåÎ∞òÎ≥µÎ∞òÎ≥µ.. Ïù¥ÎìúÎùºÎßàÎäî Í∞ÄÏ°±ÎèÑÏóÜÎã§ Ïó∞Í∏∞Î™ªÌïòÎäîÏÇ¨ÎûåÎßåÎ™®ÏóøÎÑ§ [SEP] [CLS] Ïï°ÏÖòÏù¥ ÏóÜÎäîÎç∞ÎèÑ Ïû¨ÎØ∏ ÏûàÎäî Î™áÏïàÎêòÎäî ÏòÅÌôî [SEP] [CLS] ÏôúÏºÄ ÌèâÏ†êÏù¥ ÎÇÆÏùÄÍ±¥Îç∞? ÍΩ§ Î≥ºÎßåÌïúÎç∞.. ÌóêÎ¶¨Ïö∞ÎìúÏãù ÌôîÎ†§Ìï®ÏóêÎßå ÎÑàÎ¨¥ Í∏∏Îì§Ïó¨Ï†∏ ÏûàÎÇò? [SEP]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] ÏïÑ ÎçîÎπô.. ÏßÑÏßú [MASK] [MASK]ÎÇòÎÑ§Ïöî [MASK]ÏÜåÎ¶¨ [SEP] [CLS] [UNK]... Ìè¨Ïä§ÌÑ∞Î≥¥Í≥† Ï¥àÎî©ÏòÅ [MASK]Ï§Ñ.. [MASK] [MASK] Ïò§Î≤ÑÏó∞Í∏∞ [MASK]Ï∞®‘∫Î≥ç [MASK] ÏïäÍµ¨ÎÇò [SEP] [CLS] [UNK] [SEP] [CLS] ÍµêÎèÑÏÜå Ïù¥ÏïºÍ∏∞Íµ¨Î®º.. ÏÜîÏßÅÌûà Ïû¨ÎØ∏Îäî [MASK] [MASK]. ÌèâÏ†ê Ï°∞Ï†ï [SEP] [CLS] ÏÇ¨Ïù¥Î™¨ [MASK]Í∑∏ [MASK] ÏùµÏÇ¥ PSÎü∞ [MASK]Í∏∞Í∞Ä ÎèãÎ≥¥ÏòÄÎçò ÏòÅÌôî! Ïä§ÌååÏù¥ÎçîÎß®ÏóêÏÑú ÎäôÏñ¥Î≥¥Ïù¥Í∏∞Îßå ÌñàÎçò Ïª§ [MASK]Ìã¥ ÎçòÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ÎÇò [MASK] Ïù¥ÎªêÎ≥¥ÏòÄÎã§ [SEP] [CLS] Îßâ Í±∏ÏùåÎßà [UNK] 3 [MASK]Î∂ÄÌÑ∞ [MASK]Îì±ÌïôÍµê 1ÌïôÎÖÑÏÉùÏù∏ 8ÏÇ¥Ïö©Á≤òÌôî [MASK] [UNK]. [MASK]. Î≥ÑÎ∞òÍ∞ú'\n",
      "\n",
      "'>>> ##ÎèÑ ÏïÑÍπåÏõÄ. [SEP] [CLS] Ïõê [MASK]Ïùò agriculturalÏû•Í∞êÏùÑ Ï†úÎåÄÎ°ú ÏÇ¥Î†§ÎÇ¥ÏßÄ [MASK]ÌñàÎã§. [SEP] [CLS] Î≥Ñ [MASK]Í∞úÎèÑ ÏïÑÍπùÎã§ [MASK]ÎÇòÏò®Îã§ Ïù¥ÏùëÍ≤Ω Í∏∏Ïö©Ïö∞ Ïó∞Í∏∞ÏÉùÌôúÏù¥Î™áÎÖÑ [MASK] [MASK].. Ï†ïÎßê Î∞úÎ°ú [MASK]ÎèÑ [MASK]Í≤ÉÎ≥¥Îã® ÎÇ´Í≤üÎã§ ÎÇ©Ïπò. Í∞ê [MASK]ÎßåÎ∞òÎ≥µÎ∞òÎ≥µ.. Ïù¥ÎìúÎùºÎßà [MASK] Í∞ÄÏ°±ÎèÑÏóÜÎã§ Ïó∞Í∏∞Î™ªÌïòÎäîÏÇ¨ÎûåÎßåÎ™®ÏóøÎÑ§ [SEP] [CLS] Ïï° [MASK]Ïù¥ ÏóÜÎäîÎç∞ [MASK] Ïû¨ [MASK] ÏûàÎäî [MASK]ÏïàÎêòÎäî ÏòÅÌôî [SEP] [CLS] ÏôúÏºÄ ÌèâÏ†ê [MASK] ÎÇÆÏùÄÍ±¥Îç∞? ÍΩ§ Î≥ºÎßåÌïúÎç∞.. ÌóêÎ¶¨Ïö∞ [MASK] [MASK] Ìôî [MASK]Ìï®ÏóêÎßå ÎÑàÎ¨¥ Í∏∏Îì§Ïó¨Ï†∏ ÏûàÎÇò? [SEP]'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Îã®Ïñ¥ÏôÄ Ìï¥Îãπ ÌÜ†ÌÅ∞ Ïù∏Îç±Ïä§ Í∞ÑÏùò map ÏÉùÏÑ±\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Î¨¥ÏûëÏúÑÎ°ú Îã®Ïñ¥ ÎßàÏä§ÌÇπ\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "\n",
    "    return default_data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] ÏïÑ ÎçîÎπô [MASK]. [MASK] [MASK] ÏßúÏ¶ùÎÇòÎÑ§Ïöî Î™©ÏÜåÎ¶¨ [SEP] [CLS] [UNK]... Ìè¨Ïä§ÌÑ∞Î≥¥Í≥† [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [MASK]. Ïò§Î≤ÑÏó∞Í∏∞Ï°∞Ï∞® Í∞ÄÎ≥çÏßÄ ÏïäÍµ¨ÎÇò [SEP] [CLS] [UNK] [SEP] [CLS] ÍµêÎèÑÏÜå Ïù¥ÏïºÍ∏∞Íµ¨Î®º [MASK]. ÏÜîÏßÅÌûà [MASK] [MASK] [MASK] [MASK].. ÌèâÏ†ê [MASK] [MASK] [SEP] [CLS] ÏÇ¨Ïù¥Î™¨ÌéòÍ∑∏Ïùò ÏùµÏÇ¥Ïä§Îü∞ Ïó∞Í∏∞Í∞Ä [MASK] [MASK] [MASK] ÏòÅÌôî! Ïä§ÌååÏù¥ÎçîÎß®ÏóêÏÑú ÎäôÏñ¥Î≥¥Ïù¥Í∏∞Îßå ÌñàÎçò Ïª§Ïä§Ìã¥ ÎçòÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ÎÇòÎèÑ Ïù¥ÎªêÎ≥¥ÏòÄÎã§ [SEP] [CLS] Îßâ Í±∏ÏùåÎßà [UNK] 3ÏÑ∏Î∂ÄÌÑ∞ [MASK] [MASK] 1ÌïôÎÖÑÏÉùÏù∏ 8ÏÇ¥Ïö©ÏòÅÌôî. [UNK]... Î≥ÑÎ∞òÍ∞ú'\n",
      "\n",
      "'>>> ##ÎèÑ ÏïÑÍπåÏõÄ. [SEP] [CLS] [MASK] [MASK] [MASK] Í∏¥Ïû•Í∞êÏùÑ Ï†úÎåÄÎ°ú [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [SEP] [CLS] [MASK] Î∞òÍ∞úÎèÑ ÏïÑÍπùÎã§ ÏöïÎÇòÏò®Îã§ Ïù¥ÏùëÍ≤Ω Í∏∏Ïö©Ïö∞ [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]. [MASK] Ï†ïÎßê [MASK] [MASK] [MASK] [MASK] Í∑∏Í≤ÉÎ≥¥Îã® ÎÇ´Í≤üÎã§ ÎÇ©Ïπò. Í∞êÍ∏àÎßåÎ∞òÎ≥µÎ∞òÎ≥µ.. Ïù¥ÎìúÎùºÎßàÎäî Í∞ÄÏ°±ÎèÑÏóÜÎã§ Ïó∞Í∏∞Î™ªÌïòÎäîÏÇ¨ÎûåÎßåÎ™®ÏóøÎÑ§ [SEP] [CLS] Ïï°ÏÖòÏù¥ ÏóÜÎäîÎç∞ÎèÑ Ïû¨ÎØ∏ [MASK] Î™áÏïàÎêòÎäî ÏòÅÌôî [SEP] [CLS] [MASK] [MASK] ÌèâÏ†êÏù¥ ÎÇÆÏùÄÍ±¥Îç∞? [MASK] Î≥ºÎßåÌïúÎç∞.. [MASK] [MASK] [MASK] [MASK] [MASK] ÌôîÎ†§Ìï®ÏóêÎßå ÎÑàÎ¨¥ [MASK] [MASK] [MASK] [MASK] ÏûàÎÇò? [SEP]'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÏôÄ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎ•º ÏßÄÏ†ïÌïòÏó¨ ÏÉòÌîåÎßÅÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 23269\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 2586\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_size = 10_000\n",
    "#test_size = int(0.1 * train_size)\n",
    "train_size = None\n",
    "test_size = 0.1\n",
    "\n",
    "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÎØ∏ÏÑ∏Ï°∞Ï†ï ÌõàÎ†®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjeong/DevEnv/py312/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-nsmc\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:57]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 274.00\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1092' max='1092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1092/1092 02:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.604100</td>\n",
       "      <td>3.070170</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.107300</td>\n",
       "      <td>2.869706</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.981400</td>\n",
       "      <td>2.876446</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "finetuned_model_path = \"./fine-tuned-distilbert-nsmc-mlm\"\n",
    "tokenizer.save_pretrained(finetuned_model_path)\n",
    "model.save_pretrained(finetuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='41' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/41 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 17.04\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'input text: Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî [MASK]Ïùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî ÏòÅÌôîÏùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî ÎßõÏùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî Í≤ÉÏùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî ÏûîÏùò ÎßåÎÇ®.'\n",
      "'>>> Îã¨ÏΩ§Ìïú ÍøÄÍ≥º ÌÜ°ÏèòÎäî ÌïúÏùò ÎßåÎÇ®.'\n"
     ]
    }
   ],
   "source": [
    "print(f\"'input text: {text}'\")\n",
    "topk_tokens = find_topk_for_masked(tokenizer, model, text, topk=5)\n",
    "for token in topk_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZ3y78jzXbpSmLBC0mDN3f",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ade48e3bc6d4a46a86b599e87ea406b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30d72eedc6714e21a7f200cb0abcfd33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32fa3ff8af104c4d9f23ed652c721e20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6de2a2c502be4e4fa4770ea0eb4fe94e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8eabe883b07b4d968dd2cd8bff9ca264",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6de4057a54f84d10a3dcc7e0535a86e5",
      "value": "‚Äá10570/10570‚Äá[00:15&lt;00:00,‚Äá788.93‚Äáexamples/s]"
     }
    },
    "6de4057a54f84d10a3dcc7e0535a86e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85e055a4dcaf4131ad4cad24b5b2410c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87df2842719045488595c9725e386297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed9c813e80fc43b096bda875f665b176",
      "max": 10570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ade48e3bc6d4a46a86b599e87ea406b",
      "value": 10570
     }
    },
    "8eabe883b07b4d968dd2cd8bff9ca264": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4088c8d15fb41efb56ca8295c7f25b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32fa3ff8af104c4d9f23ed652c721e20",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_30d72eedc6714e21a7f200cb0abcfd33",
      "value": "Map:‚Äá100%"
     }
    },
    "d2345c97cf9e4f4a9c1a1344c928fdf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4088c8d15fb41efb56ca8295c7f25b5",
       "IPY_MODEL_87df2842719045488595c9725e386297",
       "IPY_MODEL_6de2a2c502be4e4fa4770ea0eb4fe94e"
      ],
      "layout": "IPY_MODEL_85e055a4dcaf4131ad4cad24b5b2410c"
     }
    },
    "ed9c813e80fc43b096bda875f665b176": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
