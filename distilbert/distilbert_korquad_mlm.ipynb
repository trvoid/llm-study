{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/trvoid/llm-study/blob/main/bert/getting_started_with_distilbert_for_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cvu_6JOiK0j"
   },
   "source": [
    "# DistilBERT for MLM ÏãúÏûëÌïòÍ∏∞ (ÌïúÍµ≠Ïñ¥)\n",
    "\n",
    "**ÎÖ∏Ìä∏: distilbert-base-multilingual-casedÎ•º Í∏∞Î≥∏ Î™®Îç∏Î°ú ÏÇ¨Ïö©ÌïòÏòÄÏùå**\n",
    "\n",
    "Ïù¥ Ïã§ÏäµÏùÄ ÏïÑÎûò Î¨∏ÏÑúÏùò ÎÇ¥Ïö©ÏùÑ ÌÜ†ÎåÄÎ°ú ÏßÑÌñâÌïòÏòÄÏäµÎãàÎã§.\n",
    "\n",
    "* [2. ÎßàÏä§ÌÅ¨ Ïñ∏Ïñ¥ Î™®Îç∏(Masked Language Model) ÎØ∏ÏÑ∏Ï°∞Ï†ï](https://wikidocs.net/166833), Transformers (Ïã†Í≤ΩÎßù Ïñ∏Ïñ¥Î™®Îç∏ ÎùºÏù¥Î∏åÎü¨Î¶¨) Í∞ïÏ¢å\n",
    "* [Fine-tuning a masked language model](https://huggingface.co/learn/llm-course/en/chapter7/3), LLM Course in Hugging Face\n",
    "\n",
    "ÏÇ¨Ïö©Ìï† Î™®Îç∏Í≥º Îç∞Ïù¥ÌÑ∞ÏÖãÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
    "\n",
    "* [DistilBERT](distilbert/distilbert-base-multilingual-cased):Í∏∞Î≥∏ Î™®Îç∏ (Îã®Ïñ¥Ïóê ÎåÄÌïú Îã®Ïàú ÏûÑÎ≤†Îî©Ïù¥ ÏïÑÎãàÎùº Îß•ÎùΩÏùÑ Í≥†Î†§Ìïú ÏûÑÎ≤†Îî© ÏàòÌñâ)\n",
    "* [DistilBertForMaskedLM](https://huggingface.co/docs/transformers/model_doc/distilbert#transformers.DistilBertForMaskedLM): DistilBERT Î™®Îç∏Ïóê ÎßàÏä§ÌÅ¨ Ïñ∏Ïñ¥ Î™®Îç∏ Ï∏µÏùÑ Ï∂îÍ∞ÄÌïú Í≤ÉÏúºÎ°úÏÑú ÎßàÏä§ÌÅ¨ Ïñ∏Ïñ¥ Î™®Îç∏ ÎØ∏ÏÑ∏Ï°∞Ï†ï ÌõàÎ†®ÏùÑ ÏúÑÌïú Î™®Îç∏\n",
    "* [KorQuAD 1.0](https://huggingface.co/datasets/KorQuAD/squad_kor_v1): ÏßàÏùòÏùëÎãµ ÎØ∏ÏÑ∏Ï°∞Ï†ï ÌõàÎ†®ÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ÏÖã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î∞è Î™®Îç∏ Ï†ÅÏû¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# GPU ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏ Î∞è Ïû•Ïπò ÏÑ§Ï†ï\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:25:43.972208: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 16:25:43.980482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744183543.989090 2943846 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744183543.991702 2943846 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744183543.999729 2943846 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744183543.999735 2943846 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744183543.999736 2943846 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744183543.999737 2943846 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-09 16:25:44.002260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DistilBertForMaskedLM\n",
    "\n",
    "model_checkpoint = \"distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = DistilBertForMaskedLM.from_pretrained(model_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 119547\n",
      "model device: cuda:0\n",
      "DistilBERT number of parameters: 135M\n",
      "BERT number of parameters: 110M\n"
     ]
    }
   ],
   "source": [
    "print(f\"vocab size: {len(tokenizer)}\")\n",
    "print(f\"model device: {next(model.parameters()).device}\")\n",
    "distilbert_num_parameters = model.num_parameters() / 1_000_000\n",
    "print(f\"DistilBERT number of parameters: {round(distilbert_num_parameters)}M\")\n",
    "print(f\"BERT number of parameters: 110M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: tensor([   101,   9309,  24982, 118922,  80795,   9491,  38378,   9730,  44321,\n",
      "           123,  14646,  17730,  12638,  18589,   9379,  14871,  48387, 105197,\n",
      "         20626,  62672,   9485,  25549,    102])\n",
      "len(input_ids): 23\n",
      "token_strs: ['[CLS]', 'ÎØ∏', '##ÏÑ∏', '##Î®º', '##ÏßÄÍ∞Ä', 'Ïã¨', '##ÌïòÎ©¥', 'Ï∞®', '##Îüâ', '2', '##Î∂Ä', '##Ï†ú', '##ÏôÄ', 'Í∞ôÏùÄ', 'ÎπÑ', '##ÏÉÅ', '##Ï†Ä', '##Í∞ê', '##Ï°∞', '##ÏπòÎ•º', 'Ïãú', '##Ìñâ', '[SEP]']\n",
      "decoded_text: [CLS] ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ [SEP]\n",
      "input_ids: tensor([   101,   9309,  24982, 118922,  80795,   9491,  38378,   9730,  44321,\n",
      "           123,  14646,  17730,  12638,    103,   9379,  14871,  48387, 105197,\n",
      "         20626,  62672,   9485,  25549,    102])\n",
      "len(input_ids): 23\n",
      "token_strs: ['[CLS]', 'ÎØ∏', '##ÏÑ∏', '##Î®º', '##ÏßÄÍ∞Ä', 'Ïã¨', '##ÌïòÎ©¥', 'Ï∞®', '##Îüâ', '2', '##Î∂Ä', '##Ï†ú', '##ÏôÄ', '[MASK]', 'ÎπÑ', '##ÏÉÅ', '##Ï†Ä', '##Í∞ê', '##Ï°∞', '##ÏπòÎ•º', 'Ïãú', '##Ìñâ', '[SEP]']\n",
      "decoded_text: [CLS] ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ [MASK] ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ [SEP]\n"
     ]
    }
   ],
   "source": [
    "def test_tokenizer(tokenizer, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=14, padding=\"max_length\")\n",
    "    print(f\"input_ids: {inputs[\"input_ids\"][0]}\")\n",
    "    print(f\"len(input_ids): {len(inputs[\"input_ids\"][0])}\")\n",
    "    \n",
    "    token_strs = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "    print(f\"token_strs: {token_strs}\")\n",
    "    \n",
    "    decoded_text = tokenizer.decode(inputs[\"input_ids\"][0])\n",
    "    print(f\"decoded_text: {decoded_text}\")\n",
    "\n",
    "org_text = \"ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ\"\n",
    "text = \"ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ [MASK] ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ\"\n",
    "\n",
    "test_tokenizer(tokenizer, org_text)\n",
    "test_tokenizer(tokenizer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ ##Ïùò ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ ##Í∞Ä ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ ##Ïù¥ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ ##ÏôÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ ##ÏßÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_topk_for_masked(tokenizer, model, text, topk=5):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items() if isinstance(v, torch.Tensor)}\n",
    "\n",
    "    token_logits = model(**inputs).logits\n",
    "    #print(token_logits.shape)\n",
    "    \n",
    "    # [MASK]Ïùò ÏúÑÏπòÎ•º Ï∞æÍ≥†, Ìï¥Îãπ logitsÏùÑ Ï∂îÏ∂úÌï©ÎãàÎã§.\n",
    "    #print(torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id))\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "    #print(mask_token_index)\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    #print(mask_token_logits)\n",
    "    \n",
    "    # Í∞ÄÏû• ÌÅ∞ logitsÍ∞íÏùÑ Í∞ÄÏßÄÎäî [MASK] ÌõÑÎ≥¥Î•º ÏÑ†ÌÉùÌï©ÎãàÎã§.\n",
    "    top_5_tokens = torch.topk(mask_token_logits, topk, dim=1).indices[0].tolist()\n",
    "    \n",
    "    return top_5_tokens\n",
    "\n",
    "topk_tokens = find_topk_for_masked(tokenizer, model, text, 5)\n",
    "for token in topk_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ÅÏû¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 60407\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 5774\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"KorQuAD/squad_kor_v1\"\n",
    "dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> context: 9Ïõî 26Ïùº ÌôòÍ≤ΩÎ∂ÄÎ•º ÎπÑÎ°ØÌïú 12Í∞ú Í¥ÄÍ≥ÑÎ∂ÄÏ≤òÍ∞Ä Ìï©ÎèôÏúºÎ°ú 'ÎØ∏ÏÑ∏Î®ºÏßÄ Í¥ÄÎ¶¨ Ï¢ÖÌï©ÎåÄÏ±Ö'ÏùÑ ÌôïÏ†ïÌïòÍ≥† Î∞úÏ†Ñ¬∑ÏÇ∞ÏóÖ¬∑ÏàòÏÜ°¬∑ÏÉùÌôú Îì± 4Í∞ú Î∂ÄÎ∂ÑÏóêÏÑú Ï†ÄÍ∞ê ÎåÄÏ±ÖÏùÑ Ïã§ÏãúÌïòÎäî Í¥ÄÎ†® Î°úÎìúÎßµÏùÑ Î∞úÌëúÌñàÎã§. 7Ï°∞ 2000Ïñµ ÏõêÏùò ÏòàÏÇ∞ÏùÑ Ìà¨ÏûÖÌï¥ ÎØ∏ÏÑ∏Î®ºÏßÄ Íµ≠ÎÇ¥ Î∞∞Ï∂úÎüâÏùÑ 30% Í∞êÏ∂ïÌïòÍ≥† ÎØ∏ÏÑ∏Î®ºÏßÄ 'ÎÇòÏÅ®' ÏùºÏàòÎ•º 70%ÍπåÏßÄ Ï§ÑÏù¥Í∏∞Î°ú Ìïú Í≤ÉÏù∏Îç∞ Ïù¥Î•º ÏúÑÌï¥ Í≥µÏ†ïÎ•† 10% ÎØ∏ÎßåÏù∏ ÏÑùÌÉÑÎ∞úÏ†ÑÏÜå 9Í∏∞ Ï§ë 4Í∏∞Î•º LNG Îì± ÏπúÌôòÍ≤Ω Ïó∞Î£åÎ°ú Ï†ÑÌôòÌïòÍ≥† ÎÇ®ÏùÄ 5Í∏∞ÎèÑ ÏµúÍ≥† ÏàòÏ§ÄÏùò Î∞∞Ï∂ú Í∏∞Ï§ÄÏùÑ Ï†ÅÏö©ÌïòÎ©∞ 30ÎÖÑÏù¥ ÎÑòÏùÄ ÎÖ∏ÌõÑ ÏÑùÌÉÑÎ∞úÏ†ÑÏÜå 7Í∏∞Îäî ÏûÑÍ∏∞ ÎÇ¥ ÌèêÏáÑÌïòÍ∏∞Î°ú ÌñàÎã§. ÎòêÌïú ÎåÄÍ∏∞Î∞∞Ï∂úÏ¥ùÎüâÏ†úÎ•º Ï†ÑÍµ≠ÏúºÎ°ú ÌôïÎåÄ¬∑Í∞ïÌôîÌïòÍ≥† Î®ºÏßÄÏ¥ùÎüâÏ†úÎ•º ÏÉàÎ°ú ÎèÑÏûÖÌïòÎ©∞, ÎÖ∏ÌõÑ Í≤ΩÏú†Ï∞® 221Îßå ÎåÄÎ•º ÏûÑÍ∏∞ ÎÇ¥ 77% Ï°∞Í∏∞ ÌèêÏ∞®ÌïòÍ≥† ÏπúÌôòÍ≤Ω Ï∞®Î•º 2022ÎÖÑÍπåÏßÄ 200Îßå ÎåÄ Î≥¥Í∏âÌïòÎ©∞ ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâÌïòÍ∏∞Î°ú ÌñàÎã§. Íµ≠Ï†úÏ†ÅÏúºÎ°úÎäî ÎØ∏ÏÑ∏Î®ºÏßÄÎ•º ÌïúÏ§ë ÏñëÍµ≠Ïùò Ï†ïÏÉÅÏùòÏ†úÎ°ú Í≤©ÏÉÅÌïòÍ≥† ÎèôÎ∂ÅÏïÑ ÏßÄÏó≠ÏóêÏÑú ÌòëÏïΩÏ≤¥Í≤∞ÏùÑ Ï∂îÏßÑÌïòÎ©¥ÏÑú ÎØ∏ÏÑ∏Î®ºÏßÄ ÌôòÍ≤ΩÍ∏∞Ï§ÄÎèÑ ÏÑ†ÏßÑÍµ≠ ÏàòÏ§ÄÏúºÎ°ú Í∞ïÌôîÌï† Í≤ÉÎèÑ Ìè¨Ìï®ÌñàÎã§.'\n",
      "'>>> question: ÎØ∏ÏÑ∏Î®ºÏßÄ Ìï¥Í≤∞ÏùÑ ÏúÑÌï¥ Ï†ÑÍµ≠ÏúºÎ°ú ÌôïÎåÄ Í∞ïÌôîÎêú Í∏∞Ï°¥Ïùò Ï†úÎèÑÎäî?'\n",
      "\n",
      "'>>> context: ÌîÑÎ¶¨Ïä§ÌãÄÎ¶¨Îäî ÏõåÎßÅÌÑ¥ Í±∞Ï£º ÏãúÏ†àÏóêÎäî Îã§Î•∏ Ïùº ÎïåÎ¨∏Ïóê Ïã†Ìïô Ïó∞Íµ¨Ïóê Î™∞ÎëêÌïòÏßÄ Î™ªÌïòÏòÄÏúºÎÇò, Î¶¨Ï¶àÏóê Ïò§Î©¥ÏÑú Í∑∏Îäî Ïã†Ìïô Ïó∞Íµ¨Ïóê ÎßéÏùÄ ÏãúÍ∞ÑÏùÑ Ìà¨ÏûêÌïòÏòÄÍ≥†, Í≤∞Í≥ºÏ†ÅÏúºÎ°ú Í∑∏Ïùò Ïã†ÏïôÏùÄ ÏïÑÎ¶¨Ïö∞Ïä§Ï£ºÏùòÏóêÏÑú Ïú†ÎãàÌÖåÎ¶¨Ïñ∏ÏúºÎ°ú Ï†ïÎ¶ΩÎêòÏóàÎã§. Î¶¨Ï¶àÏóêÏÑú ÌîÑÎ¶¨Ïä§ÌãÄÎ¶¨Îäî ÏÇºÏúÑÏùºÏ≤¥ÏôÄ ÏòàÏàòÏùò ÏÑ†Ïû¨ÏÑ±(ÂÖàÂú®ÊÄß, ÏÑ±ÏûêÏù∏ ÏòàÏàòÎäî Ï≤úÏßÄÏ∞ΩÏ°∞Ï†ÑÎ∂ÄÌÑ∞ ÏÑ±Î∂ÄÏôÄ Í∞ôÏù¥ Ï°¥Ïû¨ÌñàÎã§Îäî ÍµêÎ¶¨)Îì±ÏùÑ ÏôÑÏ†ÑÌûà Î∂ÄÏ†ïÌïòÏòÄÍ≥†, Í∏∞ÎèÖÍµê ÍµêÎ¶¨ÏôÄ ÏÑ±ÏÑúÎ•º ÏÉàÎ°≠Í≤å Ìï¥ÏÑùÌïòÍ∏∞ ÏãúÏûëÌñàÎã§. Í∑∏Îäî Ïò§ÎûòÏ†ÑÎ∂ÄÌÑ∞ Ïç®Ïò§Îçò Ïã†Ìïô ÍµêÏú°Ïóê ÎåÄÌïú Ï±ÖÏù∏ „ÄäÏûêÏó∞Í≥º Í≥ÑÏãú Ï¢ÖÍµêÏùò ÏõêÎ¶¨„Äã(Institutes of Natural and Revealed Religion)Î•º Ï∂úÌåêÌïòÍ∏∞ ÏãúÏûëÌïòÏòÄÎäîÎç∞, 1772ÎÖÑÏóê 1Í∂åÏù¥ Ï∂úÌåêÎêòÏóàÍ≥† ÎßàÏßÄÎßâ 3Í∂åÏùÄ 1774ÎÖÑÏóê Ï∂úÌåêÎêòÏóàÎã§. Í∑∏Îäî Ï±ÖÏóêÏÑú ÏûêÏó∞ Ï¢ÖÍµê, Í≥ÑÏãúÏùò ÏßÑÏã§ÏÑ±ÏùÑ Îí∑Î∞õÏπ®ÌïòÎäî ÎÖºÍ±∞, Í≥ÑÏãúÎ°úÎ∂ÄÌÑ∞ ÏñªÏùÑ Ïàò ÏûàÎäî ÏßÑÏã§ Îì±ÏùÑ ÎÖºÌñàÎã§. Ïù¥ Ï±ÖÏùÄ ÏïΩ Î∞òÏÑ∏Í∏∞Í∞ÑÏùò ÏûêÏú†Ï£ºÏùò Ïã†ÌïôÏûêÎì§Ïùò Ï£ºÏû•ÏùÑ ÏöîÏïΩÌïòÏòÄÍ≥† Ïò§Îûú Í∏∞Í∞ÑÏóê Í±∏Ï≥ê Ïú†ÎãàÌÖåÎ¶¨Ïñ∏Ïùò ÎåÄÌëúÏ†ÅÏù∏ Ìï¥ÏÑ§ÏÑúÍ∞Ä ÎêòÏóàÎã§.'\n",
      "'>>> question: Ïò§Îûú Ïã†Ìïô Ïó∞Íµ¨ ÎÅùÏóê ÌîÑÎ¶¨Ïä§ÌãÄÎ¶¨Ïùò Ïã†ÏïôÏùÄ ÏïÑÎ¶¨Ïö∞Ïä§Ï£ºÏùòÎ•º Í±∞Ï≥ê Î¨¥ÏóáÏúºÎ°ú Ï†ïÎ¶ΩÎêòÏóàÎäîÍ∞Ä?'\n",
      "\n",
      "'>>> context: Í∑∏Îäî Î∞§Ïù¥ ÏÉàÎèÑÎ°ù Í∑ºÎ°úÍ∏∞Ï§ÄÎ≤ï Ï°∞Î¨∏ÏùÑ Ï∞æÏïÑ ÏïîÍ∏∞ÌïòÎ©∞ ÌòÑÏû•ÏóêÏÑú Î∞úÏÉùÌïòÎäî ÎÖ∏ÎèôÏûê Î∂àÏù¥ÏùµÏóê Ï†ÄÌï≠ÌïòÏòÄÎã§. Í∑∏Îäî ÎèôÎåÄÎ¨∏Íµ¨Ï≤≠ÏùÑ Ï∞æÏïÑÍ∞Ä Ïó¥ÏïÖÌïú ÌôòÍ≤ΩÏóê ÎåÄÌï¥ Ìò∏ÏÜåÌñàÏßÄÎßå Î∞õÏïÑÎì§Ïó¨ÏßÄÏßÄ ÏïäÏïòÎã§. Í∑∏Îäî Í∑ºÎ°úÍ∏∞Ï§ÄÎ≤ïÏÉÅÏùò Í∞êÎèÖÍ∂å ÌñâÏÇ¨Î•º ÏöîÏ≤≠ÌïòÍ∏∞ ÏúÑÌï¥ ÏãúÏ≤≠ Í∑ºÎ°úÍ∞êÎèÖÍ¥ÄÏã§ÏùÑ Ï∞æÏïÑÍ∞îÏßÄÎßå, Í∑ºÎ°úÍ∞êÎèÖÍ¥ÄÏùÄ ÌèâÌôî ÏãúÏû•Ïùò Ï∞∏ÌòπÌïú ÏñòÍ∏∞Ïóê Í¥ÄÏã¨ Ï°∞Ï∞® Î≥¥Ïù¥ÏßÄ ÏïäÏïòÎã§. Í∑∏Îäî Îã§Ïãú ÎÖ∏ÎèôÏ≤≠Ïùò Î¨∏ÏùÑ ÎëêÎìúÎ†∏ÏßÄÎßå Í≤∞Í≥ºÎäî ÎßàÏ∞¨Í∞ÄÏßÄÏòÄÎã§. Í∞ÄÎú©Ïù¥ÎÇò Ïñ¥Î†§Ïö¥ Ï°∞Í±¥ ÏÜçÏóêÏÑú Î∞úÎ≤ÑÎë•ÏπòÍ≥† ÏûàÎçò Ï†ÑÌÉúÏùºÏóêÍ≤å Í∑∏Í≤ÉÏùÄ ÎÑàÎ¨¥ÎÇò ÌÅ∞ Ï∂©Í≤©Ïù¥ÏóàÎã§. ÎÖ∏ÎèôÏù¥ÎÇò Í∑ºÎ°ú Í∏∞Ï§ÄÎ≤ïÏ°∞Ï∞® ÏÇ¨ÏóÖÏ£ºÎì§Ïùò Ìé∏Ïù¥ÎùºÎäî ÌòÑÏã§ÏùÄ Í∑∏Î•º ÌïúÎèôÏïà ÌóàÌÉà ÏÉÅÌÉúÎ°ú Î™∞ÏïÑ ÎÑ£ÏóàÎã§. Í∑∏Îäî Ï≤≠Í≥ÑÏ≤ú ÏùºÎåÄÏùò ÎÖ∏Îèô Ïã§ÌÉúÎ•º ÏßÅÏ†ë Ï°∞ÏÇ¨, ÏÑ§Î¨∏ÌïòÏó¨ Ïù¥Î•º ÌÜ†ÎåÄÎ°ú Í∑ºÎ°úÍ∏∞Ï§ÄÎ≤ï Ï§ÄÏàòÎ•º ÏöîÍµ¨ÌïòÎäî Ï≤≠ÏõêÏÑúÎ•º ÎÖ∏ÎèôÏ≤≠Ïóê ÎÉàÏúºÎÇò ÎèåÏïÑÏò® ÎãµÎ≥ÄÏùÄ Í≤ΩÎ©∏Í≥º ÎπÑÏõÉÏùå ÎøêÏù¥ÏóàÎã§. Ï≤òÏùåÏóê ÏïΩÍ∞Ñ ÎßêÌà¨Í∞Ä Ïñ¥ÎàåÌñàÎçò Í∑∏Îäî Î∂ÄÎûëÏûêÎ°ú Î™∞Î¶¨Í±∞ÎÇò, ÎÖ∏ÎèôÏ≤≠ Í≥µÎ¨¥ÏõêÎì§ÏóêÍ≤å Ï°∞Î°±Ïùò ÎåÄÏÉÅÏù¥ ÎêòÍ∏∞ÎèÑ ÌñàÎã§. Í∑∏Ïùò ÎÖ∏ÎèôÏûê Í∂åÎ¶¨ Ï≤≠ÏõêÏùÄ Ïñ∏Î°†Îì§ÎèÑ Ïô∏Î©¥ÌñàÍ≥†, Í≤ΩÌñ•Ïã†Î¨∏ Îì±ÏóêÎßå Í∞ÑÎûµÌïòÍ≤å Î≥¥ÎèÑÎêòÏóàÎã§.'\n",
      "'>>> question: Í∑∏Îäî Í∑ºÎ°úÍ∏∞Ï§ÄÎ≤ïÏÉÅÏùò Í∞êÎèÖÍ∂å ÌñâÏÇ¨Î•º ÏöîÏ≤≠ÌïòÎ†§Í≥† Ïñ¥Îäê Í≥≥ÏùÑ Ï∞æÏïÑÍ∞îÎäîÍ∞Ä?'\n"
     ]
    }
   ],
   "source": [
    "samples = dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in samples:\n",
    "    print(f\"\\n'>>> context: {row['context']}'\")\n",
    "    print(f\"'>>> question: {row['question']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples, max_length=512):\n",
    "    result = tokenizer(examples[\"question\"], \n",
    "                       examples[\"context\"],\n",
    "                       max_length=max_length, \n",
    "                       truncation=\"only_second\"\n",
    "                      )\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 8888, 37114, 57362, 9546, 48446, 10530, 9522, 119081, 25503, 118671, 136, 102, 8888, 37114, 57362, 9637, 13764, 10530, 9522, 119081, 48345, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'word_ids': [[None, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, None, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, None]]}\n",
      "['[CLS]', 'Í≥†', '##Ïñë', '##Ïù¥Í∞Ä', 'Ïñ¥', '##Îîî', '##Ïóê', 'Ïïâ', '##Ïäµ', '##Îãà', '##Íπå', '?', '[SEP]', 'Í≥†', '##Ïñë', '##Ïù¥Í∞Ä', 'Ïùò', '##Ïûê', '##Ïóê', 'Ïïâ', '##Ïäµ', '##ÎãàÎã§', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "test_examples = {\n",
    "    \"context\": [\"Í≥†ÏñëÏù¥Í∞Ä ÏùòÏûêÏóê ÏïâÏäµÎãàÎã§.\"],\n",
    "    \"question\": [\"Í≥†ÏñëÏù¥Í∞Ä Ïñ¥ÎîîÏóê ÏïâÏäµÎãàÍπå?\"],\n",
    "    \"answers\": [\n",
    "        {\n",
    "            \"text\": [\"ÏùòÏûê\"],\n",
    "            \"answer_start\": [5]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "test_result = tokenize_function(test_examples)\n",
    "print(test_result)\n",
    "token_strs = tokenizer.convert_ids_to_tokens(test_result[\"input_ids\"][0])\n",
    "print(token_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 60407\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
      "        num_rows: 5774\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Îπ†Î•∏ Î©ÄÌã∞Ïä§Î†àÎî©ÏùÑ ÏûëÎèôÏãúÌÇ§Í∏∞ ÏúÑÌï¥ÏÑú, batched=TrueÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_max_length: 512\n"
     ]
    }
   ],
   "source": [
    "print(f\"model_max_length: {tokenizer.model_max_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk_size = 128\n",
    "chunk_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 length: 429\n",
      "Review 1 length: 428\n",
      "Review 2 length: 428\n"
     ]
    }
   ],
   "source": [
    "# Slicing produces a list of lists for each feature\n",
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"Review {idx} length: {len(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated reviews length: 1285\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"Concatenated reviews length: {total_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 150'\n",
      "'>>> Chunk length: 150'\n",
      "'>>> Chunk length: 150'\n",
      "'>>> Chunk length: 150'\n",
      "'>>> Chunk length: 150'\n",
      "'>>> Chunk length: 150'\n",
      "'>>> Chunk length: 150'\n",
      "'>>> Chunk length: 150'\n",
      "'>>> Chunk length: 85'\n"
     ]
    }
   ],
   "source": [
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Î™®Îì† ÌÖçÏä§Ìä∏Îì§ÏùÑ Í≤∞Ìï©ÌïúÎã§.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Í≤∞Ìï©Îêú ÌÖçÏä§Ìä∏Îì§Ïóê ÎåÄÌïú Í∏∏Ïù¥Î•º Íµ¨ÌïúÎã§.\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # `chunk_size`Î≥¥Îã§ ÏûëÏùÄ Í≤ΩÏö∞ ÎßàÏßÄÎßâ Ï≤≠ÌÅ¨Î•º ÏÇ≠Ï†ú\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # max_len Í∏∏Ïù¥Î•º Í∞ÄÏßÄÎäî chunk Îã®ÏúÑÎ°ú Ïä¨ÎùºÏù¥Ïä§\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # ÏÉàÎ°úÏö¥ Î†àÏù¥Î∏î Ïª¨ÎüºÏùÑ ÏÉùÏÑ±\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
      "        num_rows: 132044\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
      "        num_rows: 12771\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "print(lm_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ÍµêÌñ•Í≥° 9Î≤àÏùÑ Îì£Í≥† ÍπäÏùÄ Í∞êÎ™ÖÏùÑ Î∞õÏïòÎäîÎç∞, Ïù¥Í≤ÉÏù¥ Ïù¥Îì¨Ìï¥ 1ÏõîÏóê ÌååÏö∞Ïä§Ìä∏Ïùò ÏÑúÍ≥°ÏúºÎ°ú Ïì∞Ïó¨ÏßÑ Ïù¥ ÏûëÌíàÏóê Ï°∞Í∏àÏù¥ÎùºÎèÑ ÏòÅÌñ•ÏùÑ ÎÅºÏ≥§ÏúºÎ¶¨ÎùºÎäî Í≤ÉÏùÄ ÏùòÏã¨Ìï† Ïó¨ÏßÄÍ∞Ä ÏóÜÎã§. Ïó¨Í∏∞Ïùò ÎùºÎã®Ï°∞ Ï°∞ÏÑ±Ïùò Í≤ΩÏö∞ÏóêÎèÑ Í∑∏Ïùò Ï†ÑÍ∏∞Ïóê Ï†ÅÌòÄ ÏûàÎäî Í≤ÉÏ≤òÎüº Îã®ÏàúÌïú Ï†ïÏã†Ï†Å ÌîºÎ°úÎÇò Ïã§ÏùòÍ∞Ä Î∞òÏòÅÎêú Í≤ÉÏù¥ ÏïÑÎãàÎùº Î≤†ÌÜ†Î≤§Ïùò Ìï©Ï∞ΩÍµêÌñ•Í≥° Ï°∞ÏÑ±Ïùò ÏòÅÌñ•ÏùÑ Î∞õÏùÄ Í≤ÉÏùÑ Î≥º Ïàò ÏûàÎã§. Í∑∏Î†áÍ≤å ÍµêÌñ•Í≥° ÏûëÍ≥°ÏùÑ 1839ÎÖÑÎ∂ÄÌÑ∞ 40ÎÖÑÏóê Í±∏Ï≥ê ÌååÎ¶¨ÏóêÏÑú Ï∞©ÏàòÌñàÏúºÎÇò 1ÏïÖÏû•ÏùÑ Ïì¥ Îí§Ïóê Ï§ëÎã®ÌñàÎã§. ÎòêÌïú ÏûëÌíàÏùò ÏôÑÏÑ±Í≥º ÎèôÏãúÏóê Í∑∏Îäî Ïù¥ ÏÑúÍ≥° ('"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ÍµêÌñ•Í≥° 9Î≤àÏùÑ Îì£Í≥† ÍπäÏùÄ Í∞êÎ™ÖÏùÑ Î∞õÏïòÎäîÎç∞, Ïù¥Í≤ÉÏù¥ Ïù¥Îì¨Ìï¥ 1ÏõîÏóê ÌååÏö∞Ïä§Ìä∏Ïùò ÏÑúÍ≥°ÏúºÎ°ú Ïì∞Ïó¨ÏßÑ Ïù¥ ÏûëÌíàÏóê Ï°∞Í∏àÏù¥ÎùºÎèÑ ÏòÅÌñ•ÏùÑ ÎÅºÏ≥§ÏúºÎ¶¨ÎùºÎäî Í≤ÉÏùÄ ÏùòÏã¨Ìï† Ïó¨ÏßÄÍ∞Ä ÏóÜÎã§. Ïó¨Í∏∞Ïùò ÎùºÎã®Ï°∞ Ï°∞ÏÑ±Ïùò Í≤ΩÏö∞ÏóêÎèÑ Í∑∏Ïùò Ï†ÑÍ∏∞Ïóê Ï†ÅÌòÄ ÏûàÎäî Í≤ÉÏ≤òÎüº Îã®ÏàúÌïú Ï†ïÏã†Ï†Å ÌîºÎ°úÎÇò Ïã§ÏùòÍ∞Ä Î∞òÏòÅÎêú Í≤ÉÏù¥ ÏïÑÎãàÎùº Î≤†ÌÜ†Î≤§Ïùò Ìï©Ï∞ΩÍµêÌñ•Í≥° Ï°∞ÏÑ±Ïùò ÏòÅÌñ•ÏùÑ Î∞õÏùÄ Í≤ÉÏùÑ Î≥º Ïàò ÏûàÎã§. Í∑∏Î†áÍ≤å ÍµêÌñ•Í≥° ÏûëÍ≥°ÏùÑ 1839ÎÖÑÎ∂ÄÌÑ∞ 40ÎÖÑÏóê Í±∏Ï≥ê ÌååÎ¶¨ÏóêÏÑú Ï∞©ÏàòÌñàÏúºÎÇò 1ÏïÖÏû•ÏùÑ Ïì¥ Îí§Ïóê Ï§ëÎã®ÌñàÎã§. ÎòêÌïú ÏûëÌíàÏùò ÏôÑÏÑ±Í≥º ÎèôÏãúÏóê Í∑∏Îäî Ïù¥ ÏÑúÍ≥° ('"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] Î∞îÍ∑∏ÎÑàÎäî Í¥¥ [MASK]Ïùò ÌååÏö∞Ïä§Ìä∏Î•º [MASK]Í≥† Î¨¥ÏóáÏùÑ Ïì∞Í≥†Ïûê ÌñàÎäî [MASK]? [SEP] 1839ÎÖÑ Î∞î [MASK]ÎÑàÎäî Í¥¥ÌÖåÏùò ÌååÏö∞Ïä§Ìä∏ÏùÑ Ï≤òÏùå ÏùΩÍ≥† [MASK] ÎÇ¥Ïö©Ïóê ÎßàÏùå r√®gle ÎÅåÎ†§ Ïù¥Î•º [MASK]Ïû¨ [MASK] Ìï¥ÏÑú [MASK] ÍµêÌñ•Í≥°ÏùÑ Ïì∞Î†§Îäî ÎúªÏùÑ Í∞ñÎäîÎã§. Ïù¥ ÏãúÍ∏∞ Î∞î [MASK]ÎÑàÎäî 1838ÎÖÑÏóê Îπõ ÎèÖÏ¥âÏúºÎ°ú ÏÇ∞Ï†ÑÏàòÏ†ÑÏùÑ Îã§ [UNK] ÏÉÅÌô©Ïù¥Îùº Ï¢åÏ†àÍ≥º Ïã§ÎßùÏóê Í∞ÄÎìùÌñàÏúºÎ©∞ Î©îÌîºÏä§ÌÜ†Ìé† [MASK]Î•º ÎßåÎÇòÎäî ÌååÏö∞Ïä§Ìä∏ [MASK] Ïã¨Í≤ΩÏóê Í≥µÍ∞êÌñàÎã§Í≥† ÌïúÎã§. ÎòêÌïú ÌååÎ¶¨ÏóêÏÑú ÏïÑÎ∏åÎÑ§ÌÅ¨Ïùò ÏßÄÌúòÎ°ú ÌååÎ¶¨ ÏùåÏïÖÏõê Í¥Ä [MASK]ÏïÖÎã®Ïù¥ Ïó∞Ï£ºÌïòÎäî Î≤†ÌÜ†Î≤§Ïùò'\n",
      "\n",
      "'>>> ÍµêÌñ• [MASK] [MASK]Î≤àÏùÑ [MASK]Í≥† ÍπäÏùÄ Í∞êÎ™ÖÏùÑ Î∞õÏïòÎäîÎç∞, Ïù¥Í≤ÉÏù¥ Ïù¥Îì¨Ìï¥ 1ÏõîÏóê Ìåå [MASK]Ìä∏Ïùò ÏÑúÍ≥°ÏúºÎ°ú Ïì∞Ïó¨ÏßÑ Ïù¥ ÏûëÌíàÏóê Ï°∞Í∏àÏù¥ÎùºÎèÑ ÏòÅÌñ•ÏùÑ ÎÅºÏ≥§ÏúºÎ¶¨ [MASK] Í≤ÉÏùÄ ÏùòÏã¨ [MASK] Ïó¨ÏßÄÍ∞Ä ÏóÜÎã§. Ïó¨Í∏∞Ïùò Îùº [MASK]Ï°∞ Ï°∞ÏÑ±Ïùò Í≤ΩÏö∞ÏóêÎèÑ Í∑∏Ïùò Ï†ÑÍ∏∞Ïóê Ï†ÅÌòÄ ÏûàÎäî [MASK]Ï≤òÎüº Îã®ÏàúÌïú [MASK]Ïã† [MASK] ÌîºÎ°úÎÇò Ïã§ÏùòÍ∞Ä [MASK]ÏòÅÎêú Í≤ÉÏù¥ [MASK] Î≤†ÌÜ†Î≤§ [MASK] Ìï©Ï∞ΩÍµêÌñ•Í≥° Ï°∞ÏÑ±Ïùò ÏòÅÌñ•ÏùÑ Î∞õÏùÄ Í≤ÉÏùÑ Î≥º Ïàò ÏûàÎã§. Í∑∏Î†áÍ≤å ÍµêÌñ•Í≥° ÏûëÍ≥°ÏùÑ 1839ÎÖÑÎ∂ÄÌÑ∞ 40ÎÖÑÏóê [MASK] ÌååÎ¶¨ÏóêÏÑú Ï∞©ÏàòÌñàÏúºÎÇò [MASK]ÏïÖ [MASK] Ïì¥ Îí§Ïóê Ï§ëÎã®ÌñàÎã§. ÎòêÌïú Ïûë [MASK]Ïùò [MASK]ÏÑ±Í≥º ÎèôÏãúÏóê Í∑∏Îäî Ïù¥ ÏÑúÍ≥° ('\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2\n",
    "\n",
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        # Îã®Ïñ¥ÏôÄ Ìï¥Îãπ ÌÜ†ÌÅ∞ Ïù∏Îç±Ïä§ Í∞ÑÏùò map ÏÉùÏÑ±\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Î¨¥ÏûëÏúÑÎ°ú Îã®Ïñ¥ ÎßàÏä§ÌÇπ\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "\n",
    "    return default_data_collator(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] [MASK] [MASK] [MASK] [MASK] Í¥¥ÌÖåÏùò ÌååÏö∞Ïä§Ìä∏Î•º ÏùΩÍ≥† Î¨¥ÏóáÏùÑ Ïì∞Í≥†Ïûê ÌñàÎäîÍ∞Ä? [SEP] 1839ÎÖÑ Î∞îÍ∑∏ÎÑàÎäî Í¥¥ÌÖåÏùò ÌååÏö∞Ïä§Ìä∏ÏùÑ Ï≤òÏùå ÏùΩÍ≥† Í∑∏ ÎÇ¥Ïö©Ïóê ÎßàÏùåÏù¥ ÎÅåÎ†§ Ïù¥Î•º ÏÜåÏû¨Î°ú Ìï¥ÏÑú ÌïòÎÇòÏùò ÍµêÌñ•Í≥°ÏùÑ Ïì∞Î†§Îäî ÎúªÏùÑ Í∞ñÎäîÎã§ [MASK] Ïù¥ ÏãúÍ∏∞ Î∞îÍ∑∏ÎÑàÎäî [MASK] [MASK] Îπõ ÎèÖÏ¥âÏúºÎ°ú ÏÇ∞Ï†ÑÏàòÏ†ÑÏùÑ Îã§ [UNK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] Ïã§ÎßùÏóê [MASK] [MASK] [MASK] Î©îÌîºÏä§ÌÜ†Ìé†Î†àÏä§Î•º ÎßåÎÇòÎäî [MASK] [MASK] [MASK] [MASK] Ïã¨Í≤ΩÏóê Í≥µÍ∞êÌñàÎã§Í≥† ÌïúÎã§ [MASK] ÎòêÌïú ÌååÎ¶¨ÏóêÏÑú ÏïÑÎ∏åÎÑ§ÌÅ¨Ïùò ÏßÄÌúòÎ°ú ÌååÎ¶¨ [MASK] [MASK] Í¥ÄÌòÑÏïÖÎã®Ïù¥ Ïó∞Ï£ºÌïòÎäî Î≤†ÌÜ†Î≤§Ïùò'\n",
      "\n",
      "'>>> ÍµêÌñ•Í≥° 9Î≤àÏùÑ [MASK] [MASK] ÍπäÏùÄ [MASK] [MASK] Î∞õÏïòÎäîÎç∞, Ïù¥Í≤ÉÏù¥ Ïù¥Îì¨Ìï¥ 1ÏõîÏóê ÌååÏö∞Ïä§Ìä∏Ïùò [MASK] [MASK] [MASK] Ïì∞Ïó¨ÏßÑ Ïù¥ ÏûëÌíàÏóê Ï°∞Í∏àÏù¥ÎùºÎèÑ [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] Í≤ÉÏùÄ ÏùòÏã¨Ìï† Ïó¨ÏßÄÍ∞Ä ÏóÜÎã§. Ïó¨Í∏∞Ïùò ÎùºÎã®Ï°∞ Ï°∞ÏÑ±Ïùò Í≤ΩÏö∞ÏóêÎèÑ Í∑∏Ïùò Ï†ÑÍ∏∞Ïóê Ï†ÅÌòÄ [MASK] Í≤ÉÏ≤òÎüº Îã®ÏàúÌïú Ï†ïÏã†Ï†Å ÌîºÎ°úÎÇò Ïã§ÏùòÍ∞Ä Î∞òÏòÅÎêú [MASK] [MASK] Î≤†ÌÜ†Î≤§Ïùò Ìï©Ï∞ΩÍµêÌñ•Í≥° Ï°∞ÏÑ±Ïùò [MASK] Î∞õÏùÄ Í≤ÉÏùÑ Î≥º Ïàò ÏûàÎã§. Í∑∏Î†áÍ≤å ÍµêÌñ•Í≥° ÏûëÍ≥°ÏùÑ 1839ÎÖÑÎ∂ÄÌÑ∞ 40ÎÖÑÏóê Í±∏Ï≥ê ÌååÎ¶¨ÏóêÏÑú Ï∞©ÏàòÌñàÏúºÎÇò [MASK] [MASK] [MASK] Ïì¥ [MASK] [MASK] Ï§ëÎã®ÌñàÎã§ [MASK] ÎòêÌïú ÏûëÌíàÏùò ÏôÑÏÑ±Í≥º ÎèôÏãúÏóê Í∑∏Îäî Ïù¥ ÏÑúÍ≥° [MASK]'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÏôÄ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Í∞úÏàòÎ•º ÏßÄÏ†ïÌïòÏó¨ ÏÉòÌîåÎßÅÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 118839\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 13205\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_size = 10_000\n",
    "#test_size = int(0.1 * train_size)\n",
    "train_size = None\n",
    "test_size = 0.1\n",
    "\n",
    "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÎØ∏ÏÑ∏Ï°∞Ï†ï ÌõàÎ†®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjeong/DevEnv/py312/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "batch_size = 64\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{model_name}-finetuned-korquad\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=4.0,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=False,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=downsampled_dataset[\"train\"],\n",
    "    eval_dataset=downsampled_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='414' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 05:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 67.94\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7428' max='7428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7428/7428 19:28, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.599800</td>\n",
       "      <td>2.192273</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.258800</td>\n",
       "      <td>2.054537</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.149700</td>\n",
       "      <td>1.996299</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.103300</td>\n",
       "      <td>1.967951</td>\n",
       "      <td>0.000500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "finetuned_model_path = \"./fine-tuned-distilbert-korquad-mlm\"\n",
    "tokenizer.save_pretrained(finetuned_model_path)\n",
    "model.save_pretrained(finetuned_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='207' max='207' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [207/207 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 7.11\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Î™®Îç∏ ÏÇ¨Ïö©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'input text: ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ [MASK] ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Ìï®Íªò ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ ÎèôÏãúÏóê ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏù¥ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Îã¨Î¶¨ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'input text: ÎØ∏[MASK]Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏##Î¶¨Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏##ÏπòÎäîÎ®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏##ÏπòÎ®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏##ÏùòÎ®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏##ÌÑ∞Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'input text: ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨[MASK] Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨##Ìïú Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨##Ìï¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨##Í∞Å Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨##ÌïòÍ≤å Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n",
      "'>>> ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨##Î¶¨ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ'\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\n",
    "    \"ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ [MASK] ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ\", \n",
    "    \"ÎØ∏[MASK]Î®ºÏßÄÍ∞Ä Ïã¨ÌïòÎ©¥ Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ\",\n",
    "    \"ÎØ∏ÏÑ∏Î®ºÏßÄÍ∞Ä Ïã¨[MASK] Ï∞®Îüâ 2Î∂ÄÏ†úÏôÄ Í∞ôÏùÄ ÎπÑÏÉÅÏ†ÄÍ∞êÏ°∞ÏπòÎ•º ÏãúÌñâ\"\n",
    "]\n",
    "for text in test_texts:\n",
    "    print(f\"'input text: {text}'\")\n",
    "    topk_tokens = find_topk_for_masked(tokenizer, model, text, topk=5)\n",
    "    for token in topk_tokens:\n",
    "        print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNZ3y78jzXbpSmLBC0mDN3f",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ade48e3bc6d4a46a86b599e87ea406b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30d72eedc6714e21a7f200cb0abcfd33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32fa3ff8af104c4d9f23ed652c721e20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6de2a2c502be4e4fa4770ea0eb4fe94e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8eabe883b07b4d968dd2cd8bff9ca264",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6de4057a54f84d10a3dcc7e0535a86e5",
      "value": "‚Äá10570/10570‚Äá[00:15&lt;00:00,‚Äá788.93‚Äáexamples/s]"
     }
    },
    "6de4057a54f84d10a3dcc7e0535a86e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85e055a4dcaf4131ad4cad24b5b2410c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87df2842719045488595c9725e386297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed9c813e80fc43b096bda875f665b176",
      "max": 10570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ade48e3bc6d4a46a86b599e87ea406b",
      "value": 10570
     }
    },
    "8eabe883b07b4d968dd2cd8bff9ca264": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4088c8d15fb41efb56ca8295c7f25b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32fa3ff8af104c4d9f23ed652c721e20",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_30d72eedc6714e21a7f200cb0abcfd33",
      "value": "Map:‚Äá100%"
     }
    },
    "d2345c97cf9e4f4a9c1a1344c928fdf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4088c8d15fb41efb56ca8295c7f25b5",
       "IPY_MODEL_87df2842719045488595c9725e386297",
       "IPY_MODEL_6de2a2c502be4e4fa4770ea0eb4fe94e"
      ],
      "layout": "IPY_MODEL_85e055a4dcaf4131ad4cad24b5b2410c"
     }
    },
    "ed9c813e80fc43b096bda875f665b176": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
